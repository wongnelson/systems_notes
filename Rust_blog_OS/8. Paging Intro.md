## What is Memory Protection in the Context of an Operating System?

Memory protection is a fundamental task of an operating system, responsible for isolating different programs from each other. It ensures that the memory areas of one process aren't accessible by other processes, thus preventing unwanted interference between different programs running on the same machine. This is achieved through the use of hardware features that regulate memory access.

For example, your web browser and text editor are separate processes that should not interfere with each other. Memory protection ensures that both can operate independently without having any undesirable effect on each other's functioning.

## How is Memory Protection Achieved in Embedded Systems?

Embedded systems, such as those running on some ARM Cortex-M processors, achieve memory protection through a feature called the Memory Protection Unit (MPU). The MPU allows for the definition of a limited number of memory regions with different access permissions. These permissions can include no access, read-only, or read-write access.

Here's an example: Assume you have a Cortex-M processor that allows for 8 different memory regions. Each memory region can be assigned a different access permission level.

```ascii
+-------------+--------------+
| Region      | Access Level |
+-------------+--------------+
| Region 1    | No Access    |
| Region 2    | Read-Only    |
| Region 3    | Read-Write   |
| Region 4    | No Access    |
| Region 5    | Read-Only    |
| Region 6    | Read-Write   |
| Region 7    | No Access    |
| Region 8    | Read-Only    |
+-------------+--------------+
```

On each memory access, the MPU checks the address against these regions and their associated permissions. If the address falls within a region for which it has the correct permissions, the access is allowed. Otherwise, the MPU throws an exception.

By changing the memory regions and access permissions during each process switch, the operating system can ensure that each process only accesses its own memory, thus providing isolation between different processes.

## What are the Different Approaches to Memory Protection on x86 Hardware?

On x86 hardware, there are two distinct approaches to memory protection: segmentation and paging.

### What is Segmentation?
[[16.1 Segmentation - Generalized Base and Bounds]]

Segmentation is a mechanism for memory protection that was introduced back in 1978 to increase the amount of addressable memory. Initially, CPUs only used 16-bit addresses, which limited the amount of addressable memory to 64 KiB. To make more memory accessible, additional segment registers were introduced, each containing an offset address. This offset was added to each memory access, allowing for up to 1 MiB of memory to be accessed.

The segment registers are chosen automatically by the CPU depending on the type of memory access: for fetching instructions, the code segment (`CS`) is used, for stack operations (`push/pop`), the stack segment (`SS`) is used. Other instructions use the data segment (`DS`) or the extra segment (`ES`). Later, two additional segment registers, `FS` and `GS`, were added, which can be used freely.

In the original version of segmentation, segment registers directly contained the offset and no access control was implemented. However, this changed with the introduction of the protected mode. In this mode, the segment descriptors contain an index into a local or global descriptor table. This table, in addition to containing the offset address, also contains the segment size and access permissions. By loading separate global/local descriptor tables for each process, the OS can confine memory accesses to the process’s own memory areas, thus isolating processes from each other.

Here's an example of how the Global Descriptor Table (GDT) might look:

```ascii
+--------+--------+-------------+-----------------+
| Index  |

 Offset | Segment Size| Access Perms    |
+--------+--------+-------------+-----------------+
| 0      | 0x1000 | 1024        | Read-Write      |
| 1      | 0x2000 | 2048        | Read-Only       |
| ...    | ...    | ...         | ...             |
| n      | 0xn000 | n*1024      | No Access       |
+--------+--------+-------------+-----------------+
```

## What is Paging on x86_64?

Paging is a method used by computer operating systems to manage computer memory. The x86_64 architecture employs a 4-level page table with a page size of 4 KiB. Regardless of the level, each page table contains a fixed size of 512 entries, with each entry being 8 bytes. As a result, each table is 512 * 8 B = 4 KiB large, neatly fitting into one page.

```ascii
| Level 4 Page Table |
+--------------------+
| Entry 0            |
| Entry 1            |
| ...                |
| Entry 511          |
+--------------------+
```
Each entry in this table represents an 8-byte (64-bit) value. As the table is 4 KiB in size and divided into 8-byte entries, we get 512 possible entries.

## How is the Page Table Index Derived from the Virtual Address in x86_64 Architecture?

In x86_64, the page table index for each level is directly derived from the virtual address. Bits 0–12 represent the page offset, bits 12–21 the level 1 index, bits 21–30 the level 2 index, bits 30–39 the level 3 index, and bits 39–48 the level 4 index. Each table index consists of 9 bits, as each table contains 2^9 = 512 entries. The lowest 12 bits provide the offset in the 4 KiB page (2^12 bytes = 4 KiB). Bits 48 to 64 are discarded, meaning that x86_64, despite its name, only supports 48-bit addresses rather than a full 64-bit range.

```ascii
| 64-bit virtual address                     |
| bit 48 to 64 | 39-48 | 30-39 | 21-30 | 12-21 | 0-12 |
|    Discard   | Lvl 4 | Lvl 3 | Lvl 2 | Lvl 1 | Page offset |
```
Despite the discard range (48 to 64), all bits in this range must be copies of bit 47 to maintain address uniqueness and allow for future extensions like the 5-level page table. This is known as sign-extension and is similar to the sign extension in two's complement. When an address is not correctly sign-extended, the CPU throws an exception.

## Does x86_64 Support More Than 4-Level Page Tables?

Yes, some recent CPUs, like the “Ice Lake” Intel CPUs, optionally support 5-level page tables to extend virtual addresses from 48-bit to 57-bit. However, as of now, we will focus on the standard 4-level page tables, which is the most commonly used setup.

## Can You Explain the Process of Translation in x86_64 Paging With an Example?
<span style="background:rgba(240, 200, 0, 0.2)">Note: Read chapter for diagrams</span>

Sure, let's walk through an example to understand how the translation process works in detail.

```ascii
| Lvl 4 Page Table |
+------------------+
| -> Lvl 3 Table 1 |
| -> Lvl 3 Table 2 |
+------------------+
```
In the above scenario, the physical address of the currently active level 4 page table, which is the root of the 4-level page table, is stored in the CR3 register. Each page table entry then points to the physical frame of the next level table. The entry of the level 1 table then points to the mapped frame. It's important to note that all addresses in the page tables are physical instead of virtual, because otherwise, the CPU would need to translate those addresses too, which could cause never-ending recursion.

To illustrate how page table hierarchy maps, let's use two pages with virtual addresses of 0x803FE7F000 and 0x803FE7F000. If a program tries to read from address 0x803FE7F5CE, the process would look like this:

1. Convert the address to binary and determine the page table indices and the page offset for the address.

```ascii
| Sign extension: 0 |
| Level 4 index: 1  |
| Level 3 index: 0  |
| Level 2 index: 511|
| Level 1 index: 127|
| Page offset: 0x5ce|
```

2. Walk through the page table hierarchy to determine the mapped frame for the address:

   - Start by reading the address of the level 4 table out of the CR3 register.
   - The level 4 index is 1, so we look at the entry with index 1 of that table, which tells us that the level 3 table is stored at address 16 KiB.
   - We load the level 3 table from that address and look at the entry with index 0, which points us to the level 2 table at 24 KiB.
   - The level 2 index is 511, so we look at the last entry of that page to find out the address of the level 1 table.
   - Through the entry with index 127 of the level 1 table, we finally find out that the page is mapped to frame 12 KiB, or 0x3000 in hexadecimal.
   - The final step is to add the page offset to the frame address to get the physical address 0x3000 + 0x5ce = 0x35ce.

```ascii
Step 0: CR3 -> Lvl 4 Table
Step 1: Lvl 4 entry -> Lvl 3 Table
Step 2: Lvl 3 entry -> Lvl 2 Table
Step 3: Lvl 2 entry -> Lvl 1 Table
Step 4: Lvl 1 entry -> Mapped frames
```

The permissions for the page in the level 1 table are "read-only" (r). These permissions are enforced by the hardware, and it would throw an exception if a write to that page was attempted. Permissions in higher level pages restrict the possible permissions in lower levels. For instance, if the level 3 entry is set to read-only, no pages that use this entry can be writable, even if lower levels specify read/write permissions.

It's worth noting that this example used only a single instance of each table, but there are typically multiple instances of each level in each address space. At maximum, there are one level 4 table, 512 level 3 tables (because the level 4 table has 512 entries), 512 * 512 level 2 tables (each of the 512 level 3 tables has 512 entries), and 512 * 512 * 512 level 1 tables (512 entries for each level 2 table).

## What is the Format of the Page Table in x86_64?

Page tables on the x86_64 architecture are essentially an array of 512 entries. Each entry is 8 bytes (64 bits) large. 

In Rust syntax, it could be represented as follows:

```rust
#[repr(align(4096))]
pub struct PageTable {
    entries: [PageTableEntry; 512],
}
```
The `repr` attribute signifies that page tables need to be page-aligned, i.e., aligned on a 4 KiB boundary. This ensures that a page table always fills a complete page and allows an optimization that makes entries very compact.

## What is the Structure of Each Entry in a Page Table?

Each entry in the page table has the following format:

| Bit(s)	| Name |	Meaning |
| ----------- | ---- | ------- |
| 0 |	present |	the page is currently in memory |
| 1 |	writable |	it’s allowed to write to this page |
| 2 |	user accessible |	if not set, only kernel mode code can access this page |
| 3 |	write-through caching |	writes go directly to memory |
| 4 |	disable cache |	no cache is used for this page |
| 5 |	accessed |	the CPU sets this bit when this page is used |
| 6 |	dirty |	the CPU sets this bit when a write to this page occurs |
| 7 |	huge page/null |	must be 0 in P1 and P4, creates a 1 GiB page in P3, creates a 2 MiB page in P2 |
| 8 |	global |	page isn’t flushed from caches on address space switch (PGE bit of CR4 register must be set) |
| 9-11 |	available |	can be used freely by the OS |
| 12-51 |	physical address |	the page aligned 52bit physical address of the frame or the next page table |
| 52-62 |	available |	can be used freely by the OS |
| 63 |	no execute |	forbid executing code on this page (the NXE bit in the EFER register must be set) |

Bits 12–51 are used to store the physical frame address. The remaining bits are used as flags or can be freely used by the operating system. 

## How are the Bits in a Page Table Entry Used?

The bits in a page table entry are used as follows:

- Bits 0–11 and 52–63: Since we always point to a 4096-byte aligned address, either to a page-aligned page table or to the start of a mapped frame, these bits are always zero. This is because there is no need to store these bits as the hardware can just set them to zero before using the address. The same is true for bits 52–63, because the x86_64 architecture only supports 52-bit physical addresses (similar to how it only supports 48-bit virtual addresses).
- Bits 12–51: These are used to store the physical frame address.
- Bits 0, 1, 2, 3, 4, 5, 6, 7, 8, and 63: These are used as flags with various functionalities ranging from indicating whether a page is in memory, writable, accessible by user or kernel code, whether caching is enabled, and whether execution is allowed.
- Bits 9-11 and 52-62: These bits are available and can be used freely by the operating system for any purpose.

## What are the Available Flags in a Page Table Entry?

Let's delve deeper into the flags available in a page table entry:

- **Present flag:** This flag differentiates mapped pages from unmapped ones. It can be used to temporarily swap out pages to disk when the main memory becomes full. When the page is accessed subsequently, a special exception called page fault occurs, to which the operating system can react by reloading the missing page from disk and then continuing the program.
- **Writable and no execute flags:** These control whether the contents of the page are writable or contain executable instructions, respectively.
- **Accessed and dirty flags:** These are automatically set by the CPU when a read or write to the page occurs. This information can be leveraged by the operating system, e.g., to decide which pages to swap out or whether the page contents have been modified since the last save to disk.
- **Write-through caching and disable cache flags:** These allow the control of caches for every page individually.
- **User accessible flag:** This makes a page available to userspace code, otherwise, it is only accessible when the CPU is in kernel mode. This feature can be used to make system calls faster by keeping the kernel mapped while a userspace program is running. However, the Spectre vulnerability can allow userspace programs to read these pages nonetheless.
- **Global flag:** This signals to the hardware that a page is available in all address spaces and thus does not need to be removed from the translation cache (see the section about the TLB below) on address space switches. This flag is commonly used together with a cleared user accessible flag to map the kernel code to all address spaces.
- **Huge page flag:** This allows the creation of pages of larger sizes by letting the entries of the level 2 or level 3 page tables directly point to a mapped frame. With this bit set, the page size increases by factor 512 to either 2 MiB = 512 * 4 KiB for level 2 entries or even 1 GiB = 512 * 2 MiB for level 3 entries. The advantage of using larger pages is that fewer lines of the translation cache and fewer page tables are needed.

The `x86_64` crate in Rust provides types for page tables and their entries, so you don’t need to create these structures yourself.

## What is the Translation Lookaside Buffer (TLB)?

The Translation Lookaside Buffer (TLB) is a hardware cache in the CPU used to improve the performance of translating virtual addresses to physical addresses in a paged memory system. 

A 4-level page table makes the translation of virtual addresses expensive because each translation requires four memory accesses. The TLB improves this performance by caching the last few translations. This allows the CPU to skip the page table lookups when a translation is still cached.

```ascii
+-------+   virtual address   +---------+   physical address   +-------+
|  CPU  | ------------------> |  TLB    | ------------------> | Memory|
+-------+                     +---------+                     +-------+
```

The TLB acts as a hardware cache between the CPU and memory. If the TLB has a translation cached, the CPU can skip the page table lookups, which significantly speeds up memory access.

## How Does the CPU Handle TLB Updates?

Unlike other CPU caches, the <mark style="background: #FFB8EBA6;">TLB is not fully transparent </mark>and does not update or remove translations when the contents of page tables change. This means that the operating system kernel must manually update the TLB whenever it modifies a page table.

To manually update the TLB, the CPU provides a special instruction called `invlpg` ("invalidate page") that removes the translation for the specified page from the TLB. This forces the TLB to load the translation again from the page table on the next access.

<mark style="background: #FFB8EBA6;">pink</mark>
In the context of computer systems, when we refer to a mechanism as being "transparent," we mean that it operates behind the scenes without requiring explicit management or intervention from higher-level systems or the programmer.

For instance, most modern CPUs have multiple levels of cache (L1, L2, L3, etc.) to speed up memory accesses. These caches are "transparent" in the sense that they automatically store and retrieve data as needed based on the memory access patterns of the program. The program itself doesn't need to know that these caches exist or manage them in any way - it simply reads from and writes to memory as if the caches weren't there.

### Why is the TLB transparent?
The reason the TLB doesn't automatically update is tied to its purpose and the design of modern hardware systems.

The TLB is a small, specialized cache that assists with the translation of virtual addresses to physical addresses. Its primary goal is speed. It is designed to be extremely fast to access, significantly faster than accessing the page tables in main memory. This is important because every memory access performed by the CPU requires this translation, so it happens very frequently.

If the TLB were to automatically update every time the page tables in main memory change, it would need to constantly monitor these tables. However, the page tables are often located in main memory, which is significantly slower to access than the registers where the TLB resides. Constantly checking these tables for changes would be a major performance bottleneck.

Additionally, the CPU typically isn't aware of when these page tables change. The operating system manages these tables and can change them at any time for its own reasons, such as to allocate new memory for a process, deallocate memory, change the permissions of a page, or implement features like copy-on-write. The CPU doesn't know when these changes are made, so it would have to continually check for them.

For these reasons, the responsibility of managing the TLB - including updating or invalidating entries when the page tables change - is left to the operating system. This gives the operating system the flexibility to manage memory in the way it sees fit, while still allowing the hardware to provide fast address translation for the common case where the page tables do not change.

There are some hardware features, like the x86's Page Global Enable (PGE) bit or ARM's ASID (Address Space ID), which aim to mitigate this issue and make TLB management more automatic, but the principle remains that TLB management is generally more explicit than for other types of cache.

## What should be ensured when page tables are modified?

Whenever the page tables are modified, it's crucial to ensure the TLB is updated. If the TLB isn't updated, the CPU might keep using the old translation from its cache, potentially leading to non-deterministic bugs that are very hard to debug.

For instance, imagine a situation where a page table entry pointing to a certain physical frame is updated. If the TLB isn't invalidated, it may continue to translate virtual addresses to the old physical address, leading to incorrect behavior.

## How Does the x86_64 Kernel Handle Paging?
### Does the x86_64 kernel operate on paging from the start?
Yes, the x86_64 kernel operates on paging from the start, thanks to the bootloader.

### What does the bootloader do in relation to paging setup?
The bootloader sets up a 4-level paging hierarchy for the x86_64 kernel.

### Why is paging necessary in 64-bit mode on x86_64?
Paging is mandatory in 64-bit mode on x86_64 to provide memory management and virtual addressing capabilities.

### Are all memory addresses in the kernel virtual addresses?
Yes, in the kernel, all memory addresses are virtual addresses because the kernel operates in a virtual memory environment.

### Can we access the VGA buffer at the physical address `0xb8000` directly?
No, accessing the VGA buffer at the physical address `0xb8000` is not done directly. Instead, the bootloader identity-maps the memory page containing the VGA buffer, mapping the virtual address `0xb8000` to the corresponding physical frame.

### What benefit does the setup of a paging hierarchy provide for the kernel?
The setup of a paging hierarchy makes the kernel safer by causing page fault exceptions for out-of-bounds memory accesses instead of allowing writes to random physical memory.

### Does the bootloader also set access permissions for each page in the kernel?
Yes, the bootloader sets the correct access permissions for each page in the kernel. Typically, only pages containing code are marked as executable, while only data pages are marked as writable.

## What are the control registers?
In the x86 architecture, the Control Registers (CR registers) are a set of special-purpose registers that control and configure various aspects of the processor's operation and behavior. These registers provide the CPU with control over critical system settings, such as memory management, task management, and system configuration. The x86 architecture specifies several CR registers, including:

1. CR0 (Control Register 0): CR0 is a 32-bit register that controls various operating modes and features of the processor. It includes flags for enabling or disabling features like protected mode, paging, and floating-point unit (FPU) emulation. CR0 also contains control bits for managing the cache, write protection, and the numeric error reporting mechanism.

2. CR2 (Control Register 2): CR2 is a 32-bit register used for storing the linear address of the most recent page fault that occurred in the system. When a page fault exception is triggered, the CPU automatically stores the faulting address in CR2, allowing the operating system to determine the cause and handle the exception appropriately.

3. CR3 (Control Register 3): CR3 is a 32-bit register that holds the physical base address of the page directory, which is part of the memory management unit (MMU). The page directory maps virtual addresses to physical addresses and is used for virtual memory translation. By modifying CR3, the operating system can switch between different page directories, enabling process-specific address mappings.

4. CR4 (Control Register 4): CR4 is a 32-bit register that controls various system-level features and extensions. It includes flags for enabling or disabling features such as virtual-8086 mode, virtual machine extensions (VMX), protection keys, and more. CR4 provides control over advanced processor features and architectural extensions.

These CR registers are privileged and can only be accessed by privileged instructions in kernel mode. They are essential for system-level programming, allowing the operating system to configure and manage critical aspects of the processor's behavior and functionality. The specific usage and configuration of the CR registers depend on the operating mode, processor capabilities, and the requirements of the operating system or application.

## What register is set when a page fault occurs?

When a page fault occurs, the CPU automatically sets the CR2 register to the accessed virtual address that caused the fault. This allows the fault handler to read the faulty address directly from the CR2 register.

Consider the following code snippet where we intentionally cause a page fault:

```rust
let ptr = 0xdeadbeaf as *mut u8;
unsafe { *ptr = 42; }
```

In this scenario, the address `0xdeadbeaf` is not mapped in our page tables, and thus trying to write to it will result in a page fault. The CR2 register will contain `0xdeadbeaf`, the address that caused the fault. 

The error code provided in the fault handler provides more information about the memory access that caused the fault, for example, whether it was a read or write operation, whether the page was present, etc. In this case, the `PROTECTION_VIOLATION` flag would not be set, which means that the fault occurred because the target page wasn't present.

## Can You Write to a Code Page?

The simple answer is no, at least not without causing a page fault. This is because code pages are typically mapped as read-only in the page tables to prevent accidental or malicious modifications to the executable code.

If you try to write to a code page, a page fault will occur with the `PROTECTION_VIOLATION` and `CAUSED_BY_WRITE` flags set. This indicates that the page was present, but the write operation was not allowed. Here's an example:

```rust
let ptr = 0x2031b2 as *mut u8;  // Suppose this is a code page.

// read from a code page
unsafe { let x = *ptr; }
println!("read worked");

// write to a code page
unsafe { *ptr = 42; }
println!("write worked");
```

In this case, reading from the code page works just fine, but writing to it results in a page fault. This is a key mechanism by which operating systems protect the integrity of executable code.

## How Can We Access Page Tables in Our Kernel?

To examine the page tables that define how our kernel is mapped, we can use the `Cr3::read` function from the `x86_64` crate. This function reads the CR3 register, which contains the base address of the currently active level 4 page table. 

```rust
use x86_64::registers::control::Cr3;

let (level_4_page_table, _) = Cr3::read();
println!("Level 4 page table at: {:?}", level_4_page_table.start_address());
```

The `Cr3::read` function returns a tuple of a `PhysFrame` and a `Cr3Flags` type. The `PhysFrame` represents the physical address of the level 4 page table, while the `Cr3Flags` holds various flags related to page table management. In the above snippet, we're only interested in the physical frame (i.e., the base address of the level 4 page table), so we ignore the `Cr3Flags`.

Upon execution, you might see an output similar to:

```
Level 4 page table at: PhysAddr(0x1000)
```

This output implies that the currently active level 4 page table resides at physical memory address `0x1000`.

## How Do We Access the Physical Memory Holding Page Tables?

A challenge arises when we need to access this level 4 page table, given its physical address. Directly accessing physical memory when paging is active is generally prohibited. This is a security feature to prevent programs from circumventing memory protection and accessing memory of other programs.

So, to access the physical frame holding our page table (or any physical memory in general), we need to go through some virtual page that is mapped to the desired physical frame. In this instance, we need a virtual page mapped to the physical frame at address `0x1000`.


