```toc
```
## What does Rust provide for testing?

Rust has a built-in test framework capable of running unit tests without requiring additional setup. This is accomplished by creating a function to verify some results through assertions and adding the `#[test]` attribute to the function header. The `cargo test` command will then automatically locate and execute all test functions within your crate.

Example:

```rust
#[test]
fn test_add() {
    assert_eq!(2 + 2, 4);
}
```

This example defines a simple unit test that checks if 2 plus 2 equals 4.

## What issues might arise when testing `no_std` applications such as kernels in Rust?

Rust's test framework implicitly uses the built-in test library, which in turn depends on the standard library. This dependency creates an issue for `#[no_std]` applications, like kernels, because they can't use the default test framework.

When you attempt to run `cargo test` in such projects, you'll encounter an error indicating that the `test` crate can't be found since it relies on the standard library. Although it's possible to port the test crate to a `#[no_std]` context, it's generally unstable and necessitates some workarounds, like redefining the `panic` macro.

## What are Custom Test Frameworks in Rust and how are they useful for `no_std` environments?

Rust has an unstable feature called `custom_test_frameworks` that allows for the replacement of the default test framework. This feature doesn't require any external libraries, making it compatible with `#[no_std]` environments.

It operates by collecting all functions with the `#[test_case]` attribute and then calling a user-defined runner function with the list of tests as arguments. This grants the implementation maximum control over the test process.

However, this method lacks many advanced features like `should_panic` tests that the default framework provides. But, the implementation can provide such features if needed. This is suitable for special execution environments where default implementations of these advanced features might not work. For instance, the `#[should_panic]` attribute depends on stack unwinding to catch the panics, which might be disabled for the kernel.

## How can we implement a custom test framework in Rust for a kernel?

To implement a custom test framework for a kernel, we can use the `custom_test_frameworks` feature to build a test runner function that executes each test function in a list. This function can be included only for tests using the `#[cfg(test)]` attribute.

Here's an example of how you might implement this:

```rust
// in src/main.rs

#![feature(custom_test_frameworks)]
#![test_runner(crate::test_runner)]

#[cfg(test)]
fn test_runner(tests: &[&dyn Fn()]) {
    println!("Running {} tests", tests.len());
    for test in tests {
        test();
    }
}
```

This runner prints a debug message and calls each test function in the list. The argument type `&[&dyn Fn()]` is a slice of trait object references of the `Fn()` trait, representing a list of references to types that can be called like a function.

####  `&[&dyn Fn()]`
[[Keywords#dyn]]
In the code snippet `&[&dyn Fn()]`, `&` denotes a reference, `[]` represents an array or slice, `&dyn Fn()` indicates a trait object representing a function pointer.

Here's a breakdown of each component:

- `&`: It signifies that the expression following it is a reference. In this case, it creates a reference to the array or slice that follows.
- `[]`: It represents an array or slice type.
- `&dyn Fn()`: It denotes a trait object that refers to a function pointer implementing the `Fn()` trait. The `dyn` keyword is used to indicate dynamic dispatch or runtime polymorphism. The `Fn()` trait represents a closure or function without arguments.

Putting it all together, `&[&dyn Fn()]` is a reference to an array or slice that contains trait objects representing function pointers implementing the `Fn()` trait. This construct allows you to store multiple functions with the same signature in a collection and invoke them dynamically at runtime.

Note that the `&dyn Fn()` trait object syntax is used when you want to refer to a trait object for functions without arguments. If the functions had arguments, the syntax would be `&dyn Fn(Arg1Type, Arg2Type, ...)` where `Arg1Type`, `Arg2Type`, etc., represent the types of the function arguments.

Here's an example demonstrating the usage of `&[&dyn Fn()]`:

```rust
fn greet() {
    println!("Hello!");
}

fn farewell() {
    println!("Goodbye!");
}

fn main() {
    let function_pointers: &[&dyn Fn()] = &[&greet, &farewell];

    for func in function_pointers {
        func();
    }
}
```

In this example, we have two functions `greet()` and `farewell()`, both of which have the same signature: no arguments and no return value. We create an array `function_pointers` of type `&[&dyn Fn()]`, which holds references to trait objects representing function pointers implementing the `Fn()` trait.

We initialize the `function_pointers` array with references to the `greet()` and `farewell()` functions using the `&` operator. Then, we iterate over each function pointer in the array and invoke the functions dynamically using the `func()` syntax.

When running the program, it will output:

```
Hello!
Goodbye!
```

As you can see, the `&[&dyn Fn()]` construct allows us to store multiple function pointers with the same signature in a collection and invoke them dynamically at runtime.

## How do we ensure that our custom test runner is called instead of the `start` function?

With the `custom_test_frameworks` feature, a main function that calls `test_runner` is generated. However, this function is ignored if you're using the `#[no_main]` attribute and providing your own entry point. To address this, we need to change the name of the generated function through the `reexport_test_harness_main` attribute and

 then call this renamed function from our `_start` function.

```rust
// in src/main.rs

#![reexport_test_harness_main = "test_main"]

#[no_mangle]
pub extern "C" fn _start() -> ! {
    println!("Hello World{}", "!");

    #[cfg(test)]
    test_main();

    loop {}
}
```

In this example, the name of the test framework entry function is set to `test_main` and it's called from our `_start` entry point. We use conditional compilation to add the call to `test_main` only in test contexts because the function is not generated on a normal run.

## How to write and run a simple test with our custom test framework?

With the custom test framework in place, we can now create our first test function using the `#[test_case]` attribute:

```rust
// in src/main.rs

#[test_case]
fn trivial_assertion() {
    print!("trivial assertion... ");
    assert_eq!(1, 1);
    println!("[ok]");
}
```

When you run `cargo test`, the output shows the successful execution of the `trivial_assertion` function. This function is now included in the tests slice passed to our `test_runner` function.

## What issue might we encounter after running all tests in a custom test framework?

After running all tests, our `test_runner` function returns to the `test_main` function, which in turn returns to our `_start` entry point function. As the entry point function is not allowed to return, we enter an endless loop at the end of `_start`. This becomes a problem as we want `cargo test` to exit after running all tests.

## How to Exit QEMU After Testing?

If you are developing an operating system kernel or any other `no_std` application, you may need to run it inside a virtual machine like QEMU for testing. However, since our custom test runner ends in an endless loop, we need to close QEMU manually each time we run `cargo test`. This is inefficient and especially problematic if we want to automate our tests through scripts. To address this issue, we can use QEMU's `isa-debug-exit` feature to exit QEMU programmatically from the guest system.

### What is `isa-debug-exit`?

QEMU supports a special `isa-debug-exit` device, which provides a way to exit QEMU from the guest system. We can enable this device by passing a `-device` argument to QEMU. This can be done by adding a `package.metadata.bootimage.test-args` configuration key in our `Cargo.toml`:

```toml
# in Cargo.toml

[package.metadata.bootimage]
test-args = ["-device", "isa-debug-exit,iobase=0xf4,iosize=0x04"]
```

The `bootimage` runner appends the `test-args` to the default QEMU command for all test executables. For a normal `cargo run`, the arguments are ignored. 

The `isa-debug-exit` device uses port-mapped I/O for communication. The `iobase` parameter specifies on which port address the device should live (`0xf4` is a generally unused port on the x86’s IO bus) and the `iosize` specifies the port size (`0x04` means four bytes).

The `isa-debug-exit` device is a virtual device used for testing purposes. It provides an I/O port (`0xf4` in this case) that can be written to with an exit code to signal the end of a test run to the underlying QEMU emulator.

The `iosize=0x04` parameter ensures that the I/O space reserved for the `isa-debug-exit` device is 4 bytes in size. This means that writing a 32-bit (4-byte) value to the specified I/O port (`0xf4`) will trigger the desired behavior in the emulator, allowing the test framework to communicate the test results and control the execution flow.

### How to Use `isa-debug-exit` Device?

The functionality of the `isa-debug-exit` device is very simple. When a value is written to the I/O port specified by `iobase`, it causes QEMU to exit with exit status `(value << 1) | 1`. So when we write 0 to the port, QEMU will exit with exit status `(0 << 1) | 1 = 1`, and when we write 1 to the port, it will exit with exit status `(1 << 1) | 1 = 3`.

We need to include a dependency on the `x86_64` crate to make use of port-based I/O.

```toml
# in Cargo.toml

[dependencies]
x86_64 = "0.14.2"
```

Now, we can create an `exit_qemu` function that writes to the `isa-debug-exit` port:

```rust
// in src/main.rs

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
#[repr(u32)]
pub enum QemuExitCode {
    Success = 0x10,
    Failed = 0x11,
}

pub fn exit_qemu(exit_code: QemuExitCode) {
    use x86_64::instructions::port::Port;

    unsafe {
        let mut port = Port::new(0xf4);
        port.write(exit_code as u32);
    }
}
```

The code provided defines an enumeration called `QemuExitCode` with two variants: `Success` and `Failed`. Each variant is assigned a specific value in hexadecimal format <mark style="background: #FFB8EBA6;">(`0x10` and `0x11`, respectively</mark>). This enum is used to represent the exit codes that can be used to signal the termination status of a QEMU virtual machine.

The `exit_qemu` function takes an argument of type `QemuExitCode` and is responsible for triggering the exit of the QEMU virtual machine. It uses the `x86_64` crate to access the x86 instruction set. Specifically, it imports the `Port` type from the `instructions::port` module.

Inside the function, an `unsafe` block is used because it performs low-level operations that are not covered by Rust's safety guarantees. A new `Port` instance is created, representing an I/O port on the x86 architecture, with the address `0xf4`. This specific port is commonly used as a communication interface between the guest operating system and the QEMU emulator.

The `write` method is then called on the `port` instance, passing the exit code as a 32-bit unsigned integer (`exit_code as u32`). This writes the exit code to the specified port, effectively signaling to the QEMU emulator the termination status of the virtual machine.

#### Why 0x10 and 0x11?
<mark style="background: #FFB8EBA6;">pink</mark>
The values 0x10 and 0x11 have been chosen to represent success and failure, respectively. When QEMU sees an I/O write to the specific port 0xf4 with one of these values, it knows that it should exit and that the value indicates the result of the test suite.

As for why 0x10 and 0x11 were chosen specifically, it seems to be an arbitrary choice made by the authors of the bootloader that this Rust kernel is using. The actual exit codes don’t matter much, as long as they don’t clash with the default exit codes of QEMU. For example, using exit code 0 for success is not a good idea because it becomes (0 << 1) | 1 = 1 after the <span style="background:#b1ffff">transformation</span>, which is the default exit code when QEMU fails to run. So we could not differentiate a QEMU error from a successful test run. 

An important point is that these are the values the bootloader expects to see. The 0xf3 port is a special port that QEMU monitors for an exit code when used in conjunction with a specific bootloader.

<span style="background:#b1ffff">blue</span>
The transformation mentioned here is related to how the `isa-debug-exit` device in QEMU works.

When a value is written to the I/O port associated with the `isa-debug-exit` device, it causes QEMU to exit with the exit status calculated by the formula `(value << 1) | 1`.

The choice to use the formula `(value << 1) | 1` to calculate the exit status is a design decision made by the QEMU developers. This formula ensures two things:

1. The exit status will always be odd. Since the least significant bit of the result is always set to 1 with the `| 1` operation, the binary representation of the result will always end with 1, which makes the number odd. This is useful because it differentiates these exit codes from others that might be even.
    
2. The exit status will be different for different input values. By shifting the input value left by one bit with `value << 1`, different input values will result in different exit statuses (except that they are all odd).
    
This allows guest systems to signal different exit statuses to the host system (i.e., the system running QEMU), which can be useful for debugging and testing purposes. By convention, an exit status of 0 indicates success, while non-zero exit statuses indicate different kinds of errors or exceptions. The specific values of the exit statuses can be used to communicate specific information about what caused the exit. In this case, different exit statuses are used to indicate whether the tests run by the operating system were successful.

In this formula, `value` is the value written to the I/O port. The `<<` operator is the bitwise left shift operator, which moves all bits in `value` one position to the left, effectively multiplying `value` by 2. The `|` operator is the bitwise OR operator, which sets the least significant bit of the result to 1. 

So, for instance, if `value` is 0 (indicating success), the exit status will be `(0 << 1) | 1`, which equals 1. If `value` is 1 (indicating failure), the exit status will be `(1 << 1) | 1`, which equals 3.

Therefore, in the case of the QemuExitCode enum, when `QemuExitCode::Success` (0x10) is passed to `exit_qemu`, it becomes `(0x10 << 1) | 1 = 0x21 = 33` as the exit status. Similarly, `QemuExitCode::Failed` (0x11) becomes `(0x11 << 1) | 1 = 0x23 = 35` as the exit status.

These transformed exit status values allow differentiating between a successful and failed test run, and they also do not clash with the default QEMU exit codes.

##### Why the left shift?
1. **Scalability:** With the bit shift operation, a large number of different statuses can be easily represented, because each different input value to the function will yield a different exit status. If you were to manually define each exit status, it would require a lot more effort as the number of possible statuses increases.
    
2. **Convention:** The bit shift operation helps maintain a convention that the least significant bit is always 1, indicating that the exit was triggered by the guest OS (your Rust OS in this case) via the `isa-debug-exit` device. This convention helps to distinguish these exit statuses from others that might occur.
    
3. **Space Utilization:** The left shift operation effectively "doubles" the value you're using to indicate status (before the bitwise OR operation sets the least significant bit to 1). This means you can communicate a large range of statuses using smaller numbers, which is more space-efficient.

Let's take an example using an 8-bit system for simplicity. Imagine you have two signals you want to send, represented by two different numbers. You choose `2` (binary `0010`) and `3` (binary `0011`).

When these signals are passed through the function `(value << 1) | 1`, here's what happens:

- For `2`, `(value << 1) | 1` becomes `(0010 << 1) | 0001`, which simplifies to `0100 | 0001`, resulting in `0101` or `5` in decimal.
    
- For `3`, `(value << 1) | 1` becomes `(0011 << 1) | 0001`, which simplifies to `0110 | 0001`, resulting in `0111` or `7` in decimal.
    
This transformation has now converted your signals `2` and `3` to `5` and `7`, respectively, both of which have the least significant bit set to `1`.

Now, whenever you receive a signal (an exit status), if the least significant bit is `1`, you know it came from the guest OS. You can then right-shift by 1 to get back the original signal:

- For `5` (`0101`), you right-shift by 1 to get `2` (`0010`).
- For `7` (`0111`), you right-shift by 1 to get `3` (`0011`).

The key is that no matter what signal you start with, the least significant bit in the resulting signal will always be `1`, thanks to the bitwise OR with `1`. This allows the recipient to know where the signal came from, while still allowing a wide range of signals to be sent.

This way, you can ensure that the resulting exit codes always meet the established convention (having the least significant bit set to `1`), and also represent a wide range of statuses. You're essentially encoding two pieces of information (the status and where it came from) into a single number, which is why bitwise operations are used.

#### Why 0xf4? 
The QEMU program is configured to interpret a write to the I/O port `0xf4` as a signal to terminate the emulated machine, and the value written to the port (either `0x10` or `0x11`) is interpreted as the exit status.

#### Why are the attributes listed for the enum there?
The `QemuExitCode` enum is defined with several attributes and traits. The reasons for using them in the context of `QemuExitCode` are:

1. `#[derive(Debug, Clone, Copy, PartialEq, Eq)]`: These derive procedural macros automatically implement commonly used traits for the enum.

   - `Debug`: This allows instances of `QemuExitCode` to be formatted using the `{:?}` or `{:#?}` syntax, which is useful for debugging.

   - `Clone` and `Copy`: `Clone` trait enables the `.clone()` method, which creates a copy of an object. `Copy` is a marker trait that signals to the Rust compiler that a shallow bit-wise copy is safe and can be done without calling `.clone()`. This simplifies the usage of `QemuExitCode` values, as you don't need to worry about move semantics.

   - `PartialEq` and `Eq`: These traits allow comparing instances of `QemuExitCode` for equality (`==`) and inequality (`!=`). This could be useful in conditionals where you want to check the exit code.

2. `#[repr(u32)]`: This attribute changes the underlying representation of the `QemuExitCode` enum to a `u32`. 

    By default, Rust doesn't specify the size of enum values, which can cause issues when interfacing with other languages or hardware that expects a certain size. In this case, `#[repr(u32)]` ensures that `QemuExitCode` values have the same size as a `u32`. This is essential when passing these values to QEMU through the I/O port, as the `Port::write` method expects a `u32` value.

In the given context, these attributes and traits simplify the use of `QemuExitCode` and ensure its correct operation when interfacing with QEMU.

#### Why do we need unsafe?
This block of code is marked as `unsafe` because it uses raw hardware operations that could lead to undefined behavior if not used correctly.

Let's break it down:

- `Port::new(0xf4)`: This line creates a new `Port` instance representing an I/O port at the address `0xf4`. This operation itself is safe, but accessing an arbitrary I/O port could potentially cause problems if the port address is incorrect or the port is not intended to be accessed directly.
    
- `port.write(exit_code as u32)`: This line writes an exit code to the port. Writing to an I/O port is a low-level operation that directly interacts with the hardware. It's considered unsafe because if used improperly it could result in undefined behavior. For example, writing the wrong values or writing to the wrong port could cause the system to crash or behave unpredictably.
    

In Rust, the `unsafe` keyword is used to mark blocks of code that perform operations which could potentially violate the memory safety guarantees that Rust provides. The programmer is essentially promising to the compiler that the operations within the block are used correctly and won't lead to undefined behavior.

In this case, the code is marked as `unsafe` because it's performing low-level operations that directly interact with the hardware. These operations need to be handled with care to avoid causing issues, and so they're encapsulated within an `unsafe` block to indicate this to the programmer and the compiler.

### How to Differentiate Between a Successful and Failed Test Run?

In order to differentiate between a successful test run and a failure, we define a `QemuExitCode` enum with variants `Success` and `Failed`. The enum is marked as `#[repr(u32)]` to represent each variant by a `u32` integer. The `exit_qemu` function will use this enum to specify the exit code. The idea is to exit with the success exit code if all tests succeeded and with the failure exit code otherwise.

Finally, we update our `test_runner` to call the `exit_qemu` function after all tests have run:

```rust
// in src/main.rs

fn test_runner(tests: &[&dyn Fn()]) {
    println!("Running {} tests", tests.len());
    for test in tests {
        test();
    }
    exit_qemu(QemuExitCode::Success);
}
```

Now, when we run `cargo test`, QEMU will close immediately after executing the tests. However, we will encounter another problem: `cargo test` considers all error codes other than 0 as a failure. Therefore, even though we pass our `Success` exit code, `cargo test` still interprets the test as failed.

## How to Configure QEMU Exit Status for Successful Test Runs?

By default, QEMU and `cargo test` treat any exit code other than 0 as a failure. This is problematic because, in our setup, even successful test executions result in a non-zero exit code. 

The solution is to configure `bootimage` to map a specified exit code to the conventional success exit code (0). This is achieved by adding the `test-success-exit-code` configuration key to your `Cargo.toml`:

```toml
# in Cargo.toml

[package.metadata.bootimage]
test-args = […]
test-success-exit-code = 33         # (0x10 << 1) | 1
```

Here, `bootimage` will consider the exit code 33 (which our successful tests produce) as a success, and therefore, `cargo test` will also interpret it as a success. In this configuration, `bootimage` maps our `Success` exit code to the conventional exit code 0.

GPT:
The reason for using the number 33 for the test-success-exit-code is related to how the isa-debug-exit device of QEMU works.

As the given text explains, when a value is written to the I/O port associated with the isa-debug-exit device, QEMU will exit with an exit status calculated as (value << 1) | 1.

In the case of the Success variant of the QemuExitCode enum, the underlying value is 0x10 or 16 in decimal. If we apply the calculation (value << 1) | 1 to this value, we get (16 << 1) | 1, which simplifies to 32 | 1, and finally to 33.

Therefore, when QEMU exits after a successful test run, the exit code is 33. The test-success-exit-code configuration key in the Cargo.toml file is used to tell the bootimage tool that an exit code of 33 from QEMU means the tests were successful. Without this, any non-zero exit code would be considered a failure by default. This way, QEMU, bootimage, and cargo's test runner all agree on what constitutes a successful test run.

## How Can We Print Test Results to the Console?

We can print the test output to the console by sending the data from our kernel to the host system. While there are various ways to do this (like using a TCP network interface), setting up a networking stack can be complex. Hence, we can use a simpler method: the serial port.

## What is a Serial Port and How Can We Use it?

A serial port is an old interface standard that isn't commonly found in modern computers. It's simple to program and can redirect the bytes sent over serial to the host’s standard output or a file.

On x86 systems, chips implementing a serial interface are called UARTs (Universal Asynchronous Receiver/Transmitter). There are several UART models, but the common ones today are all compatible with the 16550 UART. 

The 16550 UART (Universal Asynchronous Receiver-Transmitter) is a widely used integrated circuit (IC) that serves as a serial communication interface between a computer and external devices. It is commonly used for asynchronous serial communication, allowing data to be transmitted and received one bit at a time.

The 16550 UART provides several features that enhance the reliability and efficiency of serial communication. Some of its key features include:

1. FIFO (First-In-First-Out) Buffer: The 16550 UART includes a built-in buffer that stores incoming and outgoing data. This buffer helps in reducing CPU overhead by allowing data to be transferred in larger chunks, improving the overall performance of the serial communication.
    
2. Baud Rate Generator: The UART supports various baud rates, which determine the speed at which data is transmitted over the serial connection. The built-in baud rate generator in the 16550 UART allows flexible configuration of baud rates to match the requirements of the communication protocol.
    
3. Interrupt Support: The 16550 UART can generate interrupts to notify the CPU when specific events occur, such as the availability of incoming data or the completion of data transmission. This helps in efficient data handling and allows the CPU to perform other tasks while waiting for serial communication events.
    
4. Error Detection and Parity: The UART supports error detection mechanisms, such as parity checking, to ensure data integrity during transmission. Parity bits can be used to detect and correct errors in the received data.
    

The 16550 UART has been widely used in computer systems, including personal computers, servers, embedded systems, and other devices that require serial communication. It has become a standard UART implementation and has been incorporated into many computer architectures and operating systems.

We can use the `uart_16550` crate to initialize the UART and send data over the serial port. This crate can be added as a dependency to your `Cargo.toml`:

```toml
# in Cargo.toml

[dependencies]
uart_16550 = "0.2.0"
```

## How to Initialize the UART and Create a Static Writer Instance?

We create a new serial module to initialize the UART. Here's how we can do it:

```rust
// in src/main.rs

mod serial;

// in src/serial.rs

use uart_16550::SerialPort;
use spin::Mutex;
use lazy_static::lazy_static;

lazy_static! {
    pub static ref SERIAL1: Mutex<SerialPort> = {
        let mut serial_port = unsafe { SerialPort::new(0x3F8) };
        serial_port.init();
        Mutex::new(serial_port)
    };
}
```

Just like with the VGA text buffer, we use `lazy_static` and a `spinlock` to create a static writer instance. By using `lazy_static` we can ensure that the `init` method is called exactly once during its first use.

### Why 0x3F8?
In the given code snippet, `0x3F8` is the I/O port address of the serial port being used. The value `0x3F8` represents the base I/O address of the first serial port (COM1) on an x86 architecture. 

Serial ports on x86 systems are assigned specific I/O port addresses for communication. The I/O port addresses are used to read from and write to the serial port's registers, which control various aspects of serial communication such as data transfer, baud/bit rate, and interrupts.

The value `0x3F8` is the standard I/O port address for COM1, but it may vary depending on the specific system configuration. Other common addresses for serial ports include `0x2F8` for COM2, `0x3E8` for COM3, and `0x2E8` for COM4.

By using `0x3F8`, the code is initializing and creating a `SerialPort` object representing the serial port at the specified I/O port address.

## How to Implement the `serial_print!` and `serial_println!` Macros?

To make the serial port easily usable, we can add `serial_print!` and `serial_println!` macros. Here's how to implement them:

```rust
// in src/serial.rs

#[doc(hidden)]
pub fn _print(args: ::core::fmt::Arguments) {
    use core::fmt::Write;
    SERIAL1.lock().write_fmt(args).expect("Printing to serial failed");
}

/// Prints to the host through the serial interface.
#[macro_export]
macro_rules! serial_print {
    ($($arg:tt)*) => {
        $crate::serial::_print(format_args!($($arg)*));
    };
}

/// Prints to the host through the serial interface, appending a newline.
#[macro_export]
macro_rules! serial_println {
    () => ($crate::serial_print!("\n"));
    ($fmt:expr) => ($crate::serial_print!(concat!($fmt, "\n")));
    ($fmt:expr, $($arg:tt)*) => ($crate::serial_print!(
        concat!($fmt, "\n"), $($arg)*));
}
```
### Why .expect()?
In Rust, the `.expect()` method is a way to handle errors and panic with a custom error message if an error occurs. It is typically used with the `Result` type, which represents the result of an operation that can either be successful (`Ok`) or contain an error (`Err`).

### Why use $crate?
In Rust, macros are expanded at the compile time before linking libraries together. That means macros do not have any knowledge of the context in which they are used, which includes the paths to the other modules or items defined in the crate.

The `$crate::` prefix is used to refer to the root of the current crate within a macro. This is necessary because macros can be used in many different contexts, and you don't know where they'll be called from. By using `$crate::`, you ensure that you're always referring to the `serial_print!` macro from the root of the crate, no matter where the `serial_println!` macro is invoked from. 

This is especially important when you're working with a macro from a different crate. If you didn't use `$crate::`, and instead just wrote `serial_print!`, then Rust would look for `serial_print!` in the current scope where the `serial_println!` macro is being invoked, which might not be what you want. But when you write `$crate::serial_print!`, Rust knows to look for `serial_print!` in the crate where `serial_println!` is defined, which is the intended behavior. 

Thus, the `$crate::` prefix is crucial for properly accessing items in your crate's root from within macros.

## How to Use `serial_print!` and `serial_println!` Macros in Test Code?

We can replace our print and println macros in the test code with `serial_print!` and `serial_println!` macros:

```rust
// in src/main.rs

#[cfg(test)]
fn test_runner(tests: &[&dyn Fn()]) {
    serial_println!("Running {} tests", tests.len());
    […]
}

#[test_case]
fn trivial_assertion() {
    serial_print!("trivial assertion... ");
    assert_eq!(1, 1);
    serial_println!("[ok]");
}
```

Note: The `serial_println!` macro lives directly under the root namespace because we used the `#[macro_export]` attribute. Therefore, importing it via `use crate::serial::serial_println` won't work.

## How to View Serial Output from QEMU in the Console?

To view the serial output from QEMU in the console, you can use the `-serial` argument to redirect the output to stdout. This can be done by adding the `-serial` argument to the `test-args` in your `Cargo.toml`:

```toml
# in Cargo.toml

[package.metadata.bootimage]
test-args = [
    "-device", "isa-debug-exit,iobase=0xf4,iosize=0x04", "-serial", "stdio"
]
```

When you run `cargo test` now, you should see the test output directly in the console.

## What Happens When a Test Fails?

When a test fails, you'll still see the output inside QEMU because our panic handler is using `println`. For example, if you modify your `trivial_assertion` test to `assert_eq!(0, 1)`, you'll see the panic message printed to the VGA buffer, while other test output is printed to the serial port.

## How to Print Panic Messages to the Console?

It would be useful to also see panic messages in the console. To do this, you can use conditional compilation to define a different panic handler in test mode:

```rust
// in src/main.rs

// our existing panic handler
#[cfg(not(test))] // new attribute
#[panic_handler]
fn panic(info: &PanicInfo) -> ! {
    println!("{}", info);
    loop {}
}

// our panic handler in test mode
#[cfg(test)]
#[panic_handler]
fn panic(info: &PanicInfo) -> ! {
    serial_println!("[failed]\n");
    serial_println!("Error: {}\n", info);
    exit_qemu(QemuExitCode::Failed);
    loop {}
}
```

In this panic handler for tests, we use `serial_println!` instead of `println!` and then exit QEMU with a failure exit code. Note that we still need an endless loop after the `exit_qemu` call because the compiler does not know that the `isa-debug-exit` device causes a program exit.

## How to Hide the QEMU Window?

Since we can see all test output in the console now, we no longer need the QEMU window that pops up for a short time. We can hide it by passing the `-display none` argument to QEMU:

```toml
# in Cargo.toml

[package.metadata.bootimage]
test-args = [
    "-device", "isa-debug-exit,iobase=0xf4,iosize=0x04", "-serial", "stdio",
    "-display", "none"
]
```

Now, QEMU runs completely in the background and no window gets opened anymore. This is not only less annoying, but also allows our test framework to run in environments without a graphical user interface, such as CI services or SSH connections.

## How Does the Timeout Mechanism Work in Testing?

During testing, an issue might arise where a test never returns, potentially causing the test runner to hang indefinitely. This problem can be provoked by different scenarios such as:

- The bootloader failing to load our kernel, causing the system to reboot endlessly.
- The BIOS/UEFI firmware failing to load the bootloader, again causing endless rebooting.
- The CPU enters a `loop {}` statement at the end of some of our functions due to a malfunction of the QEMU exit device.
- Hardware causing a system reset, for example, when a CPU exception is not caught.

To prevent tests stuck in an endless loop from blocking `cargo test` forever, the `bootimage` tool sets a timeout of 5 minutes for each test executable by default. If a test does not finish within this time, it is marked as failed and a “Timed Out” error is printed to the console.

This is how you can set the timeout in your `Cargo.toml`:

```toml
# in Cargo.toml

[package.metadata.bootimage]
test-timeout = 300          # (in seconds)
```
The `test-timeout` key is used to configure the timeout duration (in seconds). So, in this case, the timeout would be 5 minutes (300 seconds).

## How to Automate Test Status Printing?

Having to manually add print statements for every test can be tedious. To overcome this, you can create a `Testable` trait to automatically print these messages. Here's an example of how you can implement this:

```rust
// in src/main.rs

pub trait Testable {
    fn run(&self) -> ();
}

impl<T> Testable for T
where
    T: Fn(),
{
    fn run(&self) {
        serial_print!("{}...\t", core::any::type_name::<T>());
        self();
        serial_println!("[ok]");
    }
}
```

In this case, the `Testable` trait has a single method `run`. It is implemented for all types `T` that implement the `Fn()` trait. The `run` function prints the function name, runs the function, and then prints "\[ok]" if the function does not panic.

You can now modify your `test_runner` function to use the `Testable` trait:

```rust
// in src/main.rs

#[cfg(test)]
pub fn test_runner(tests: &[&dyn Testable]) {
    serial_println!("Running {} tests", tests.len());
    for test in tests {
        test.run();
    }
    exit_qemu(QemuExitCode::Success);
}
```
This way, you no longer need to manually print the test status for each test.

### What's core::any::type_name::<\T>()?
The `core::any::type_name::<T>()` function in Rust is used to obtain the name of a type as a string. It's a debug utility and is useful when you want to print or log the name of a type for debugging or testing purposes. 

In your case, the `core::any::type_name::<T>()` function is used in the context of running tests on your operating system. It's used in the `run` method of your `Testable` trait implementation to print the name of the test that's being run. Here's how it works:

```rust
serial_print!("{}...\t", core::any::type_name::<T>());
```

This line will print something like `my_module::my_test...` to the serial console just before `my_test` is run. This gives you an immediate feedback about which test is currently running, which can be useful for identifying which test causes a panic or other issue.

#### Why would it print the function name?
In Rust, each function has its own unique type. This is true for both free functions and associated functions (including methods). These types are anonymous, which means you can't refer to them by name in your own code, but internally they do have names that Rust's type system uses.

The `core::any::type_name::<T>()` function is a way to get a string representation of a type's name. When it is used with a function, it returns the fully qualified path to that function, which includes the function's name.

So when `core::any::type_name::<T>()` is called within the `Testable` trait implementation where `T` is a function, the returned string is essentially the name of the function, because that's the type's name.

## How to Test the VGA Buffer?

Now that you have a functional test framework, you can start creating tests for your VGA buffer implementation. Here are some examples:

A simple test to verify that `println` works without panicking:

```rust
// in src/vga_buffer.rs

#[test_case]
fn test_println_simple() {
    println!("test_println_simple output");
}
```

A test to ensure that no panic occurs even if many lines are printed and lines are shifted off the screen:

```rust
// in src/vga_buffer.rs

#[test_case]
fn test_println_many() {
    for _ in 0..200 {
        println!("test_println_many output");
    }
}
```

A test to verify that the printed lines appear on the screen:

```rust
// in src/vga_buffer.rs

#[test_case]
fn test_println_output() {
    let s = "Some test string that fits on a single line";
    println!("{}", s);
    for (i, c) in s.chars().enumerate() {
        let screen_char = WRITER.lock().buffer.chars[BUFFER_HEIGHT - 2][i].read();
        assert_eq!(char::from(screen_char.ascii_character), c);
    }
}
```
This test function prints a string using `println` and then iterates over the screen characters of the static `WRITER`, which represents the VGA text buffer. It ensures that each character of the string appears in the VGA text buffer.

You can imagine creating many more test functions that would test other features and capabilities of your VGA buffer implementation, like testing long lines, newlines, non-printable characters, and so on.

## How to Conduct Integration Tests in Rust?

Integration tests are crucial to ensure that different components of your codebase work correctly together. In Rust, the convention is to put integration tests in a separate `tests` directory at the project root, alongside the `src` directory. Both the default test framework and custom test frameworks automatically find and execute all tests in this directory.

Since each integration test in Rust is its own separate executable, each test needs to define its own entry point function. Here's an example integration test named `basic_boot` that illustrates this:

```rust
// in tests/basic_boot.rs

#![no_std]
#![no_main]
#![feature(custom_test_frameworks)]
#![test_runner(crate::test_runner)]
#![reexport_test_harness_main = "test_main"]

use core::panic::PanicInfo;

#[no_mangle] // don't mangle the name of this function
pub extern "C" fn _start() -> ! {
    test_main();

    loop {}
}

fn test_runner(tests: &[&dyn Fn()]) {
    unimplemented!();
}

#[panic_handler]
fn panic(info: &PanicInfo) -> ! {
    loop {}
}
```

Note that since integration tests are separate executables, you must provide all the crate attributes (`no_std`, `no_main`, `test_runner`, etc.) again. The entry point function `_start` calls the test entry point function `test_main`.

At this stage, running `cargo test` will result in an endless loop because the panic handler loops indefinitely. You can exit QEMU by using the `ctrl+c` keyboard shortcut.

## How to Create a Library to Aid Integration Testing?

To make the necessary functions available to your integration test, you need to create a library separate from your `main.rs`. This library can be included by other crates and integration test executables. 

Start by creating a new `src/lib.rs` file:

```rust
// src/lib.rs

#![no_std]
```

This file is automatically recognized by cargo. The library is a separate compilation unit, so you need to specify the `#![no_std]` attribute again.

Next, move the test functions and attributes from `main.rs` to `lib.rs`:

```rust
// in src/lib.rs

#![cfg_attr(test, no_main)]
#![feature(custom_test_frameworks)]
#![test_runner(crate::test_runner)]
#![reexport_test_harness_main = "test_main"]

use core::panic::PanicInfo;

pub trait Testable {
    fn run(&self) -> ();
}

impl<T> Testable for T
where
    T: Fn(),
{
    fn run(&self) {
        serial_print!("{}...\t", core::any::type_name::<T>());
        self();
        serial_println!("[ok]");
    }
}

pub fn test_runner(tests: &[&dyn Testable]) {
    serial_println!("Running {} tests", tests.len());
    for test in tests {
        test.run();
    }
    exit_qemu(QemuExitCode::Success);
}

pub fn test_panic_handler(info: &PanicInfo) -> ! {
    serial_println!("[failed]\n");
    serial_println!("Error: {}\n", info);
    exit_qemu(QemuExitCode::Failed);
    loop {}
}

/// Entry point for `cargo test`
#[cfg(test)]
#[no_mangle]
pub extern "C" fn _start() -> ! {
    test_main();
    loop {}
}

#[cfg(test)]
#[panic_handler]
fn panic(info: &PanicInfo) -> ! {
    test_panic_handler(info)
}
```

Note that you've made `test_runner` public and didn't apply the `cfg(test)` attribute to it. This makes `test_runner` available to executables and integration tests.

## How to Adjust Main.rs to Use the New Library?

With your new library in place, you need to update `main.rs` to use it:

```rust
// in src/main.rs

#![no_std]
#![no_main]
#![feature(custom_test_frameworks)]
#![test_runner(blog_os::test_runner)]
#![reexport_test_harness_main = "test_main"]

use core::panic::PanicInfo;
use blog_os::println;

#[no_mangle]
pub extern "C" fn _start() -> ! {
    println!("Hello World{}", "!");

    #[cfg(test)]
    test_main();

    loop {}
}

/// This function is called on panic.
#[cfg(not(test))]
#[panic_handler]
fn panic(info: &PanicInfo) -> ! {
    println!("{}", info);
    loop {}
}

#[cfg(test)]
#[panic_handler]
fn panic(info: &PanicInfo) -> ! {
    blog_os::test_panic_handler(info)
}
```

The library can be used like a normal external crate. It is called `blog_os`, like your crate. The above code uses the `blog_os::test_runner` function in the `test_runner` attribute and the `blog_os::test_panic_handler` function in the `cfg(test)` panic handler. It also imports the `println` macro to make it available to `_start` and panic functions.

At this point, both `cargo run` and `cargo test` should work. However, `cargo test` will still result in an endless loop (exit with `ctrl+c`). To fix this, you need to use the required library functions in your integration test.

## How to Complete the Integration Test in Rust?

In Rust, completing an integration test involves importing the necessary components from a library, similar to how you would in your `src/main.rs`. Here's an example of how to complete your test by importing components from a library named `blog_os`:

```rust
// in tests/basic_boot.rs

#![test_runner(blog_os::test_runner)]

#[panic_handler]
fn panic(info: &PanicInfo) -> ! {
    blog_os::test_panic_handler(info)
}
```

Here, instead of reimplementing the test runner, we use the `test_runner` function from our library by changing the `#![test_runner(crate::test_runner)]` attribute to `#![test_runner(blog_os::test_runner)]`. The `test_runner` stub function in `basic_boot.rs` is no longer necessary, so we remove it. For our panic handler, we call the `blog_os::test_panic_handler` function like we did in our `main.rs`.

With these changes, `cargo test` should now exit normally again. Running it will compile and run the tests for `lib.rs`, `main.rs`, and `basic_boot.rs` separately in succession. However, since neither `main.rs` nor the `basic_boot` integration test has any functions annotated with `#[test_case]`, it will report "Running 0 tests" for these.

## How to Add Tests to the Integration Test File?

Tests can be added to the `basic_boot.rs` file in the same way you would add tests to any Rust code. For example, to test that the `println` function works without panicking, as was done in the VGA buffer tests, you could do the following:

```rust
// in tests/basic_boot.rs

use blog_os::println;

#[test_case]
fn test_println() {
    println!("test_println output");
}
```

Running `cargo test` now, you should see that it finds and executes the test function. While this test may seem redundant right now, in the future, the `_start` functions of your `main.rs` and `lib.rs` may expand and call various initialization routines before running the `test_main` function. These expanded functionalities can create a different environment for each test.

By testing `println` in a `basic_boot` environment without calling any initialization routines in `_start`, you can ensure that `println` works right after booting. This is crucial because `println` is often relied upon for printing panic messages, for example.

## What Are Some Potential Future Integration Tests?

Integration tests have the benefit of being treated as entirely separate executables, which allows for complete control over the environment. This makes it possible to test how the code interacts with the CPU or hardware devices. Here are some examples of potential future tests:

**CPU Exceptions**: The CPU throws an exception when the code performs invalid operations such as dividing by zero. The kernel can register handler functions for these exceptions. An integration test could verify whether the correct exception handler is called when a CPU exception occurs, or whether execution continues correctly after a resolvable exception.

**Page Tables**: Page tables define which memory regions are valid and accessible. By modifying the page tables, it's possible to allocate new memory regions, such as when launching programs. An integration test could modify the page tables in the `_start` function and verify that the modifications have the desired effects in `#[test_case]` functions.

**Userspace Programs**: Userspace programs are programs with limited access to the system’s resources. They don't have access to kernel data structures or to the memory of other programs. An integration test could launch userspace programs that perform forbidden operations and verify that the kernel prevents all of them.

## How to Create Tests that Should Panic?

Rust's standard library provides a `#[should_panic]` attribute for creating tests expected to fail. These can be handy, for instance, when validating that a function fails when an incorrect argument is passed. However, this attribute is unsupported in `#[no_std]` crates as it needs support from the standard library.

Even though you can't use the `#[should_panic]` attribute in your kernel, you can create a similar behavior by designing an integration test that exits with a success error code from the panic handler. Let's start creating such a test with the name `should_panic`:

```rust
// in tests/should_panic.rs

#![no_std]
#![no_main]

use core::panic::PanicInfo;
use blog_os::{QemuExitCode, exit_qemu, serial_println};

#[panic_handler]
fn panic(_info: &PanicInfo) -> ! {
    serial_println!("[ok]");
    exit_qemu(QemuExitCode::Success);
    loop {}
}
```

The test above is not yet complete as it doesn't define a `_start` function or any of the custom test runner attributes. Let's add the missing parts:

```rust
// in tests/should_panic.rs

#![feature(custom_test_frameworks)]
#![test_runner(test_runner)]
#![reexport_test_harness_main = "test_main"]

#[no_mangle]
pub extern "C" fn _start() -> ! {
    test_main();

    loop {}
}

pub fn test_runner(tests: &[&dyn Fn()]) {
    serial_println!("Running {} tests", tests.len());
    for test in tests {
        test();
        serial_println!("[test did not panic]");
        exit_qemu(QemuExitCode::Failed);
    }
    exit_qemu(QemuExitCode::Success);
}
```
In this code, instead of reusing the `test_runner` from `lib.rs`, the test defines its own `test_runner` function that exits with a failure exit code when a test returns without panicking (we want our tests to panic). If no test function is defined, the runner exits with a success error code.

## How to Create a Test That Should Fail?

Now, we can create a test that should fail:

```rust
// in tests/should_panic.rs

use blog_os::serial_print;

#[test_case]
fn should_fail() {
    serial_print!("should_panic::should_fail...\t");
    assert_eq!(0, 1);
}
```
In this test, `assert_eq` is used to assert that 0 and 1 are equal. Of course, this fails, so our test panics as desired. Note that we need to manually print the function name using `serial_print!` here because we don’t use the `Testable` trait.

When we run the test through `cargo test --test should_panic`, it is successful because the test panicked as expected. However, when we comment out the assertion and run the test again, we see that it indeed fails with the “test did not panic” message.

## What is the Drawback of This Approach?

The major drawback of this approach is that it only works for a single test function. If you have multiple `#[test_case]` functions, only the first function will be executed. This is because the execution cannot continue after the panic handler has been called. As of now, there's no known good way to solve this problem.

## What are No Harness Tests?

"No Harness" tests are a kind of integration test that you can utilize in Rust. For tests that only have a single test function, you can disable the test runner and run the test directly in the `_start` function. The test is then treated like a normal executable.

## How do I disable the harness flag for my tests in Rust?

The harness flag for tests can be disabled in the `Cargo.toml` file. This is how you can disable the harness flag for a test named "should_panic":

```toml
[[test]]
name = "should_panic"
harness = false
```

When this flag is set to false, both the default test runner and the custom test runner feature are disabled.

## Can you give an example of how to write a No Harness test?

Sure. Let's take a look at a simplified `should_panic` test in which the test runner-related code has been removed:

```rust
// in tests/should_panic.rs

#![no_std]
#![no_main]

use core::panic::PanicInfo;
use blog_os::{exit_qemu, serial_print, serial_println, QemuExitCode};

#[no_mangle]
pub extern "C" fn _start() -> ! {
    should_fail();
    serial_println!("[test did not panic]");
    exit_qemu(QemuExitCode::Failed);
    loop{}
}

fn should_fail() {
    serial_print!("should_panic::should_fail...\t");
    assert_eq!(0, 1);
}

#[panic_handler]
fn panic(_info: &PanicInfo) -> ! {
    serial_println!("[ok]");
    exit_qemu(QemuExitCode::Success);
    loop {}
}
```

In this test, the `should_fail()` function is directly called from our `_start()` function. The test will exit with a failure exit code if it returns. If a panic occurs, the `panic()` function is called, it logs an "[ok]" message, and exits QEMU with a success code.

## When might it be useful to disable the harness attribute?

Apart from creating `should_panic` tests, disabling the harness attribute can be helpful for complex integration tests, particularly when individual test functions have side effects and need to be executed in a specific order.