## Q: Why do most systems opt for physical addressing in SRAM cache?

A: Most systems opt for physical addressing in SRAM cache because it is straightforward for multiple processes to have blocks in the cache at the same time and to share blocks from the same virtual pages. With physical addressing, the cache does not have to deal with protection issues because access rights are checked as part of the address translation process.

## Q: How does a physically addressed cache work with virtual memory?

A: A physically addressed cache works with virtual memory by performing address translation before the cache lookup. The process can be visualized as shown in the following diagram:

Virtual Address  -->  Address Translation  -->  Physical Address  -->  Cache Lookup

In this process, the virtual address is first translated into a physical address using page table entries. These page table entries can be cached just like any other data words.

## Q: What are the advantages of using physical addressing in SRAM cache?

Physical addressing in SRAM (Static Random Access Memory) cache has several advantages:

1. **Simplicity**: The use of physical addresses simplifies the design and implementation of the cache, as it avoids the complexity associated with managing virtual-to-physical address translation.

2. **Elimination of Alias Issues**: In a system using virtual addressing, multiple virtual addresses can be mapped to the same physical memory location, leading to "aliasing". The use of physical addresses eliminates this issue as every unique memory location will have a unique physical address.

3. **Coherency**: Physical addressing maintains memory coherency, particularly in multiprocessor systems where each processor may have a different set of page table entries. Coherency means that all processors see the same data when they access the same physical address.

4. **Avoids Translation Overhead**: With physical addressing, you avoid the overhead of translating virtual addresses to physical addresses. This can lead to improved performance in certain situations.

5. **Deterministic Behavior**: Physical addressing often leads to more deterministic behavior, as the location of data in the cache is directly related to its physical address. This can be beneficial in real-time systems where predictable timing is crucial.

However, there are also disadvantages of using physical addressing, such as the requirement to have all physical addresses available before cache access (which may not be the case if the MMU (Memory Management Unit) hasn't yet translated the virtual address). Therefore, the decision to use physical or virtual addressing in a cache system depends on the specific requirements of the system in question.


## Q: Can you provide an example of how physical addressing works in SRAM cache?

A: Let's consider a system with two processes, `P1` and `P2`, both running concurrently. Both processes have the same virtual page `V` mapped to different physical pages `P1` and `P2`.

Now, let's say `P1` first loads page `V` into its cache. Later, `P2` tries to access the same virtual page `V`. Since the cache uses physical addresses, `P2` will see the same physical page `P1` that `P1` had loaded earlier, rather than its own physical page `P2`. As a result, `P2` will be able to access the data from the cache, allowing for efficient sharing of data between processes.

Process P1: Virtual Page V --> Physical Page P1 --> Cache
Process P2: Virtual Page V --> Physical Page P1 (Shared from Cache)
