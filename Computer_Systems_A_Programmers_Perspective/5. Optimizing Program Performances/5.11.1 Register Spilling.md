## What is the critical path in a data-flow graph representation of a program?

The critical path in a data-flow graph representation of a program indicates a fundamental lower bound on the time required to execute a program. If there is a chain of data dependencies in a program where the sum of all the latencies along that chain equals T, then the program will require at least T cycles to execute.

Consider the following code:
```
a = b + c;
d = e + f;
g = a + d;
```
We can represent this code in a data-flow graph as follows:

```
    b --\
        +--> a --> g
    c --/
    |
    e --\
        +--> d
    f --/
```
In this representation, each node represents a computation, and edges indicate data dependencies. For example, the computation of a depends on the values of b and c, and the computation of g depends on the values of a and d.

Suppose that the latencies of each addition operation are 1 cycle. Then, the critical path in this data-flow graph is the path from b to a to g, which has a total latency of 2 cycles. This means that the minimum number of cycles required to execute this code is 2.

## What are throughput bounds and how do they impose a lower bound on execution time?

Throughput bounds of functional units impose a lower bound on the execution time for a program. Assume that a program requires a total of N computations of some operation, the microprocessor has C functional units capable of performing that operation, and these units have an issue time of I. Then the program will require at least N · I/C cycles to execute.

Example:
Consider a program that needs to perform 200 floating-point additions, and the microprocessor has 4 functional units that can perform floating-point additions. Assume that each addition has a latency of 3 cycles and can be issued every cycle (I = 1 cycle). The functional units can only perform 1 operation at a time (C = 1).

Using the formula, we have:

N = 200 (total computations) 
C = 4 (number of functional units) 
I = 1 (issue time of each operation)

Thus, the program will require at least N · I/C = 200 · 1/4 = 50 cycles to execute. This is the lower bound on the execution time imposed by the throughput bounds of the functional units.

## What is register spilling?

Register spilling occurs when a program has a degree of parallelism P that exceeds the number of available registers. In this situation, the compiler resorts to spilling, storing some of the temporary values in memory, typically by allocating space on the run-time stack.

## How does register spilling affect the performance of loop unrolling?

Register spilling can negatively impact the performance of loop unrolling. As the number of loop variables exceeds the number of available registers, the program must allocate some on the stack. This can lead to no improvement or even worsening of CPEs (Cycles Per Element) with increased unrolling.

#### How to prevent register spilling?
Preventing register spilling entirely is difficult since the number of registers is limited, and the number of variables in a loop may exceed the number of available registers. However, there are some techniques that can help mitigate its impact on performance.

<mark style="background: #FFB8EBA6;">One approach</mark> is to reduce the number of variables used in the loop by using arrays or structures to group related variables. This can help reduce register pressure by allowing multiple variables to be stored in a single register.

<span style="background:#d3f8b6">Another approach</span> is to use compiler options or directives to control register allocation and usage. For example, some compilers allow you to specify which variables should be stored in registers, or to reserve specific registers for certain variables.

It is important to consider register spilling when optimizing performance-critical loops, as it can have a significant impact on the loop's Cycles Per Element (CPE) performance.

<mark style="background: #FFB8EBA6;">Consider the following code snippet:</mark>
```c
struct data {
    int a;
    int b;
    int c;
    int d;
};

void foo(struct data* arr, int n) {
    int sum = 0;
    for (int i = 0; i < n; i++) {
        sum += arr[i].a * arr[i].b + arr[i].c * arr[i].d;
    }
    // do something with sum
}
```
In this example, the variables a, b, c, and d are grouped together in a structure, which allows them to be accessed using a single pointer. This reduces the number of variables used in the loop and helps to reduce register pressure.

2.  <span style="background:#d3f8b6">Using compiler options</span> or directives to control register allocation and usage:
```c
#pragma GCC push_options
#pragma GCC optimize ("no-omit-frame-pointer")
int foo(int* arr, int n) {
    register int sum asm("r0") = 0;
    register int tmp1 asm("r1");
    register int tmp2 asm("r2");
    for (int i = 0; i < n; i++) {
        tmp1 = arr[i];
        tmp2 = arr[i+1];
        sum += tmp1 * tmp2;
    }
    return sum;
}
#pragma GCC pop_options
```
In this example, the `register` keyword is used to indicate that the variables `sum`, `tmp1`, and `tmp2` should be stored in registers if possible. The `asm` keyword is used to specify which registers to use. The `#pragma` directives are used to specify additional compiler options, such as disabling frame pointer omission. These options and directives can be used to control register allocation and usage and to reduce register pressure.

## How does register spilling change the accumulator update process in loop unrolling?

When register spilling occurs, the accumulator update process changes, resulting in more memory access operations. Consider the following accumulator update in 10x10 unrolling:

`vmulsd (%rdx), %xmm0, %xmm0  // acc0 *= data[i]`

The accumulator is kept in register `%xmm0`, and the program can simply read `data[i]` from memory and multiply it by this register.

In 20x20 unrolling, the accumulator update process becomes more complex:
```c
vmovsd 40(%rsp), %xmm0
vmulsd (%rdx), %xmm0, %xmm0
vmovsd %xmm0, 40(%rsp)
```
The accumulator is kept as a local variable on the stack, at offset 40 from the stack pointer. The program must read both its value and the value of `data[i]` from memory, multiply them, and store the result back to memory. This increased complexity can negatively impact performance.