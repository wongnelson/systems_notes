## What are signed and unsigned arithmetic in C?

### What data types support signed and unsigned arithmetic in C?

Integer data types support signed and unsigned arithmetic in C.

### What is the difference between signed and unsigned numbers in C?

Signed numbers can have positive or negative values, while unsigned numbers can only have non-negative values.

### Are most numbers in C signed by default?

Yes, most numbers in C are signed by default.

### How can you create an unsigned constant in C?

To create an unsigned constant in C, you can add the character `U` or `u` as a suffix to the constant. For example, `12345U` or `0x1A2Bu`.
## How does C handle conversions between unsigned and signed integers?

### What is the conversion between unsigned and signed integers in C?

In C, it is possible to convert between unsigned and signed integers. The C standard does not specify precisely how this conversion should be made, but most systems follow the rule that the underlying bit representation of the number does not change when converting between signed and unsigned integers.

### How does the rule of preserving the underlying bit representation affect the conversion process?

The rule of preserving the underlying bit representation has the effect of applying the function `U2Tw` when converting from unsigned to signed, and `T2Uw` when converting from signed to unsigned, where `w` is the number of bits for the data type.

### What is the `U2Tw` function?

The `U2Tw` function is a conversion function that converts an unsigned integer to a two's complement signed integer. According to the rule that the underlying bit representation of the number does not change, when converting from unsigned to signed, small numbers (less than or equal to the maximum positive value of the signed data type) preserve their numeric value, while large numbers (greater than the maximum positive value) are converted to negative values.

Conversions can happen due to explicit casting, as in the following code:
```c
int tx, ty;
unsigned ux, uy;

tx = (int) ux;
uy = (unsigned) ty;
```

Alternatively, they can happen implicitly when an expression of one type is assigned to a variable of another, as in the following code:
```c
int tx, ty;
unsigned ux, uy;

tx = ux; /* Cast to signed */
uy = ty; /* Cast to unsigned */
```
## How do you print signed and unsigned integers using printf in C?

When printing numeric values with `printf`, the directives `%d`, `%u`, and `%x` are used to print a number as a signed decimal, an unsigned decimal, and in hexadecimal format, respectively. Note that `printf` does not make use of any type information, and so it is possible to print a value of type `int` with directive `%u` and a value of type `unsigned` with directive `%d`. For example:
```c
int x = -1;
unsigned u = 2147483648; /* 2 to the 31st */

printf("x = %u = %d\n", x, x);
printf("u = %u = %d\n", u, u);
```
When compiled as a 32-bit program, it prints the following:
```c
x = 4294967295 = -1
u = 2147483648 = -2147483648
```

## What nonintuitive behavior arises due to C's handling of expressions containing combinations of signed and unsigned quantities?

### What does C do when it performs an operation with one signed and one unsigned operand?

When C performs an operation with one signed and one unsigned operand, it implicitly casts the signed argument to unsigned and performs the operation assuming the numbers are nonnegative.

### Why does this convention make little difference for standard arithmetic operations?

This convention makes little difference for standard arithmetic operations because the arithmetic operations on signed and unsigned numbers are the same when both operands are nonnegative.

### What types of operators lead to nonintuitive results?

Relational operators such as `<` and `>` can lead to nonintuitive results when used with signed and unsigned operands.

### Can you provide an example of such a nonintuitive result?

For example, consider the comparison `-1 < 0U`. Since the second operand is unsigned, the first one is implicitly cast to unsigned, and hence the expression is equivalent to the comparison `4294967295U < 0U`, which is false.

## How do you convert between integers having different word sizes while retaining the same numeric value?

When converting from a smaller to a larger data type, you can perform zero extension for unsigned numbers and sign extension for two's-complement numbers.

For zero extension, add leading zeros to the representation of the unsigned number. For example:

`B2Uw(u→) = B2Uw′(u→′)`

For sign extension, add copies of the most significant bit (sign bit) to the representation of the two's-complement number. For example:

`B2Tw(x→) = B2Tw′(x→′)`

## What is an example of converting between integers of different sizes?

Consider the following code snippet:
```c
short sx = -12345;        /* -12345 */
unsigned short usx = sx;  /* 53191 */
int x = sx;               /* -12345 */
unsigned ux = usx;        /* 53191 */

printf("sx = %d:\t", sx);
show_bytes((byte_pointer) &sx, sizeof(short));
printf("usx = %u:\t", usx);
show_bytes((byte_pointer) &usx, sizeof(unsigned short));
printf("x = %d:\t", x);
show_bytes((byte_pointer) &x, sizeof(int));
printf("ux = %u:\t", ux);
show_bytes((byte_pointer) &ux, sizeof(unsigned));
```
When run as a 32-bit program on a big-endian machine that uses a two's-complement representation, this code prints the output:
```c
sx = -12345:   cf c7
usx = 53191:   cf c7
x = -12345:    ff ff cf c7
ux = 53191:    00 00 cf c7
```
We can see that the two's-complement representation of -12,345 and the unsigned representation of 53,191 are identical for a 16-bit word size. However, they differ for a 32-bit word size. In particular, -12,345 has hexadecimal representation 0xFFFFCFC7, while 53,191 has hexadecimal representation 0x0000CFC7. The former has been sign extended—16 copies of the most significant bit 1, having hexadecimal representation 0xFFFF, have been added as leading bits. The latter has been extended with 16 leading zeros, having hexadecimal representation 0x0000.

## In a 3-bit system, the leftmost bit has a weight of -4, why?
In a 3-bit two's complement system, the leftmost bit (also known as the most significant bit) has a weight of -2^(w-1), where w is the number of bits in the system.

For a 3-bit system, w=3, so the leftmost bit has a weight of -2^(3-1) = -4. This is because in two's complement, the leftmost bit is the sign bit and represents the sign of the number. If the sign bit is 1, the number is negative, and if it's 0, the number is non-negative. Since there are only 3 bits in the system, the range of non-negative numbers is from 0 to 2^3-1 = 7, and the range of negative numbers is from -2^(3-1) = -4 to -1.

## How can sign extension preserve the value of a two's-complement number?

Sign extension preserves the value of a two's-complement number because the combined effect of adding a bit of weight -2^w and converting the bit with weight -2^(w-1) to one with weight 2^(w-1) is to preserve the original numeric value. For example, when expanding from word size w = 3 to w = 4 by sign extension, bit vector `[101]` represents the value -4 + 1 = -3. Applying sign extension gives bit vector `[1101]` representing the value -8 + 4 + 1 = -3.
