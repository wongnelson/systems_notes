``
### How can concurrent programming be achieved using processes?

The simplest way to build a concurrent program is with processes, using familiar functions such as `fork`, `exec`, and `waitpid`. A natural approach for building a concurrent server is to accept client connection requests in the parent process and then create a new child process to service each new client.

### How does a server accept connection requests from clients and fork child processes?

Suppose we have a server that is listening for connection requests on a listening descriptor (say, 3). When the server accepts a connection request from a client, it returns a connected descriptor (say, 4). After accepting the connection request, the server forks a child, which gets a complete copy of the server's descriptor table. The child closes its copy of the listening descriptor (3), and the parent closes its copy of the connected descriptor (4), since they are no longer needed.
```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/types.h>
#include <sys/socket.h>
#include <netinet/in.h>

#define PORT 8080
#define BACKLOG 5

void handle_connection(int connected_descriptor) {
    // Child process code to handle the connection
    char buffer[1024];
    int bytes_received = recv(connected_descriptor, buffer, 1024, 0);
    buffer[bytes_received] = '\0';
    printf("Received: %s\n", buffer);
    send(connected_descriptor, buffer, bytes_received, 0);
    close(connected_descriptor);
    exit(0);
}

int main() {
    int listening_descriptor, connected_descriptor;
    struct sockaddr_in server_address, client_address;
    socklen_t client_address_size;
    pid_t child_pid;

    listening_descriptor = socket(AF_INET, SOCK_STREAM, 0);
    server_address.sin_family = AF_INET;
    server_address.sin_port = htons(PORT);
    server_address.sin_addr.s_addr = htonl(INADDR_ANY);
    bind(listening_descriptor, (struct sockaddr *) &server_address, sizeof(server_address));
    listen(listening_descriptor, BACKLOG);

    while (1) {
        client_address_size = sizeof(client_address);
        connected_descriptor = accept(listening_descriptor, (struct sockaddr *) &client_address, &client_address_size);
        child_pid = fork();
        if (child_pid == 0) {
            close(listening_descriptor);
            handle_connection(connected_descriptor);
        } else {
            close(connected_descriptor);
        }
    }

    return 0;
}
```

### Why is it crucial for the parent to close its copy of the connected descriptor?

Since the connected descriptors in the parent and child each point to the same file table entry, it is crucial for the parent to close its copy of the connected descriptor. Otherwise, the file table entry for the connected descriptor will never be released, and the resulting memory leak will eventually consume the available memory and crash the system.

### How does the server handle multiple clients concurrently?

Suppose that after the parent creates the child for the first client, it accepts a new connection request from a second client and returns a new connected descriptor (say, 5). The parent then forks another child, which begins servicing its client using connected descriptor 5. At this point, the parent is waiting for the next connection request, and the two children are servicing their respective clients concurrently.

## 12.1.1 A Concurrent Server Based on Processes
------------------------------------------_code/conc/echoserverp.c_

```c

1	#include "csapp.h"
2	void echo(int connfd);
3	
4	void sigchld_handler(int sig)
5	{
6		while (waitpid(−1, 0, WNOHANG) > 0)
7			;
8		return;
9	}
10	
11	int main(int argc, char **argv)
12	{
13		int listenfd, connfd;
14		socklen_t clientlen;
15		struct sockaddr_storage clientaddr;
16
17		if (argc != 2) {
18			fprintf(stderr, "usage: %s <port>\n", argv[0]);
19			exit(0);
20		}
21	
22		Signal(SIGCHLD, sigchld_handler);
23		listenfd = Open_listenfd(argv[1]);
24		while (1) {
25			clientlen = sizeof(struct sockaddr_storage);
26			connfd = Accept(listenfd, (SA *) &clientaddr, &clientlen);
27			if (Fork() == 0) {
28				Close(listenfd); /* Child closes its listening socket */
29				echo(connfd);	 /* Child services client */
30				Close(connfd);	 /* Child closes connection with client */
31				exit(0);	 /* Child exits */
32			}
33			Close(connfd); /* Parent closes connected socket (important!) */
34		}
35	}
```

#### Figure 12.5 Concurrent echo server based on processes.

The parent forks a child to handle each new connection request.

### How do we handle zombie children in a concurrent server based on processes?

Since servers typically run for long periods of time, you must include a `SIGCHLD` handler that reaps zombie children (lines 4-9). Since `SIGCHLD` signals are blocked while the `SIGCHLD` handler is executing, and Linux signals are not queued, the `SIGCHLD` handler must be prepared to reap multiple zombie children.

The body of the function contains a loop that repeatedly calls the `waitpid` function with the `WNOHANG` option (line 6). The `waitpid` function retrieves the status of a child process and can be used to reap zombie child processes. The `WNOHANG` option specifies that `waitpid` should return immediately if there are no child processes to be reaped, instead of blocking until a child process terminates.

The loop continues to call `waitpid` until it returns a value less than or equal to zero, indicating that there are no more child processes to be reaped. The `-1` argument to `waitpid` specifies that it should wait for any child process.

Finally, the function returns without doing anything (line 8). This is because the `SIGCHLD` handler does not need to return any specific value, and its purpose is solely to reap zombie child processes.

By installing this `SIGCHLD` handler, the parent process is able to properly clean up its child processes and avoid resource leaks.

### Why do parent and child processes need to close their respective copies of `connfd`?

The parent and the child must close their respective copies of `connfd` (lines 33 and 30, respectively). As mentioned, this is especially important for the parent, which must close its copy of the connected descriptor to avoid a memory leak.

### How does the reference count in the socket's file table entry affect the connection to the client?

Because of the reference count in the socket's file table entry, the connection to the client will not be terminated until both the parent's and child's copies of `connfd` are closed, as the child process inherits a copy of the parent's file descriptors, including the file descriptor for the socket that is connected to the client.

## 12.1.2 Pros and Cons of Processes

### What are the pros and cons of processes for concurrent programming?

#### Pros:

-   <mark style="background: #FFB8EBA6;">Processes have a clean model for sharing state information between parents and children</mark>: file tables are shared and user address spaces are not.
-   Having separate address spaces for processes is an advantage, as it is impossible for one process to accidentally overwrite the virtual memory of another process, which eliminates a lot of confusing failures.

#### Cons:

-   Separate address spaces make it more difficult for processes to share state information. To share information, they must use explicit IPC (interprocess communications) mechanisms.
-   Process-based designs tend to be slower because the overhead for process control and IPC is high.

<mark style="background: #FFB8EBA6;">pink</mark>
Processes in Unix-like operating systems have a clean model for sharing state information between parents and children through the use of interprocess communication (IPC) mechanisms. The following are a few common IPC mechanisms:

1.  File Descriptors: File descriptors are a low-level mechanism for sharing data between processes. When a child process is created using the `fork` function, it inherits a copy of all the open file descriptors from the parent process. This allows the parent and child processes to communicate through the file descriptors, such as by reading and writing to a shared file.
    
2.  Pipes: Pipes are a special type of file descriptor that allow processes to communicate with each other by sending and receiving data. A pipe is created using the `pipe` function, and the parent and child processes can communicate through the pipe by reading from and writing to the file descriptors that are returned by `pipe`.
**When to use?**
Pipes are a useful form of IPC (inter-process communication) for parent-child processes in the following scenarios:

1.  Simple data exchange: When you need a straightforward mechanism for transferring data between a parent process and its child process, pipes provide an easy-to-use solution. They offer a unidirectional data flow, where the parent can write data to the pipe and the child can read from it, or vice versa.
    
2.  Data streaming: Pipes are well-suited for streaming data between processes, such as when the output of one process (e.g., a command-line tool) is used as the input for another process. This is commonly used in Unix-like systems for chaining commands together with the pipe operator (|).
    
3.  Parent-child synchronization: Pipes can be used for simple synchronization between parent and child processes. For example, a parent process can wait for the child to complete a task by reading from the pipe, and the child can signal completion by writing data to the pipe.
    
4.  Process isolation: When you want to keep parent and child processes separate and limit their interaction, pipes can be a good choice. Since pipes provide a clear boundary between processes, they can help maintain process isolation and prevent unintended interference.
    
5.  Portability: Pipes are widely supported across different operating systems, making them a portable choice for IPC.
    

However, pipes have some limitations, such as being unidirectional and not suitable for complex data structures or larger data exchanges. In cases where bidirectional communication, complex data structures, or larger data exchanges are needed, other IPC mechanisms like sockets, message queues, or shared memory might be more appropriate.

    
3.  Signals: Signals are a mechanism for sending notifications between processes. A process can send a signal to another process using the `kill` function, and the receiving process can handle the signal by installing a signal handler using the `signal` function.
    
4.  Shared Memory: Shared memory is a mechanism for sharing data between processes by mapping a region of memory that is shared between the processes. The parent and child processes can communicate through the shared memory region by reading and writing to the shared memory.
	Example:
 ```c
#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/shm.h>
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

#define SHMSZ 27 // size of the shared memory

int main()
{
    char c;
    int shmid;
    key_t key;
    char *shm, *s;

    // create a key to identify the shared memory
    key = 5678;

    // create the shared memory segment with this key
    shmid = shmget(key, SHMSZ, IPC_CREAT | 0600);

    // attach the shared memory to the process's data space
    shm = shmat(shmid, NULL, 0);

    // set the first character of the shared memory to '*'
    *shm = '*';

    // fork the process to create the child process
    pid_t pid = fork();

    // check if this is the child process
    if (pid == 0) {
        // child process - wait for the parent to change the first character
        while (*shm != '#')
            sleep(1);
        // read the rest of the shared memory
        for (s = shm + 1; *s != NULL; s++)
            putchar(*s);
        putchar('\n');
        // detach the shared memory from the child process's data space
        shmdt(shm);
        // exit the child process
        exit(0);
    }
    else {
        // parent process - write to the shared memory
        s = shm + 1;
        for (c = 'a'; c <= 'z'; c++)
            *s++ = c;
        *s = NULL;
        // change the first character of the shared memory to '#'
        *shm = '#';
        // wait for the child process to finish
        wait(NULL);
        // remove the shared memory
        shmctl(shmid, IPC_RMID, NULL);
        // exit the parent process
        exit(0);
    }
    return 0;
}
```
This code demonstrates how a parent-child process can communicate through shared memory. The parent process creates a shared memory segment and writes to it, and the child process reads from it. The parent process sets the first character of the shared memory to '\*', and the child process waits until it changes to '#', which indicates that the data is ready to be read. The parent process then writes the alphabet letters 'a' to 'z' to the shared memory, and the child process reads and prints them. The parent process then removes the shared memory after the child process finishes.

**When to use shared memory?**
Shared memory is the best option when multiple processes need to share data quickly and efficiently. It is faster than other interprocess communication (IPC) mechanisms such as pipes or sockets, as it avoids the overhead of copying data between processes. Additionally, shared memory allows for random access to the shared data, whereas other IPC mechanisms may require the data to be read sequentially.

**What are drawbacks of shared memory?**
However, shared memory does not provide any synchronization mechanisms to coordinate access to the shared data, so it is important to use semaphores or other synchronization primitives to avoid race conditions.

Shared memory is also most suitable for small amounts of data that are frequently read and written, as creating and accessing shared memory regions incurs some overhead.

**What's a practical use of shared memory?**
A practical real-life example of using shared memory is a high-performance cache system in a web server environment. Consider a scenario where multiple worker processes or threads are serving web requests. These worker processes or threads need to access certain shared data, like configuration settings, cached responses, or frequently accessed database results.

In this scenario, the data size is relatively small, but the access frequency is high because multiple worker processes or threads are continuously reading and potentially updating the shared data. Using shared memory for storing this data can help improve performance and reduce the overhead of inter-process communication.

By storing the shared data in shared memory, worker processes or threads can directly access the shared data without the need for message passing or other forms of inter-process communication. This can help reduce latency and improve the overall performance of the web server.

However, it is important to implement proper synchronization mechanisms, like semaphores or mutexes, to ensure that shared data remains consistent and to avoid race conditions when multiple worker processes or threads are accessing and updating the data simultaneously.

5.  Sockets: Sockets are a mechanism for communication between processes over a network. Sockets provide a flexible and powerful mechanism for interprocess communication, and can be used for communication between processes on the same system or between processes on different systems.


## 12.1

After the parent closes the connected descriptor in line 33 of the concurrent server in Figure 12.5, the child is still able to communicate with the client using its copy of the descriptor. Why?

**Answer**: The child process inherits a copy of the connected descriptor when the parent forks it. As a result, both the parent and the child have their own copies of the connected descriptor. When the parent closes its copy of the descriptor in line 33, it does not affect the child's copy. The child can still communicate with the client using its own copy of the connected descriptor because the kernel maintains a reference count in the associated file table. The kernel will not close a file until the reference counter goes to 0, so as long as the child's end of the connection remains open, it can continue to communicate with the client.

## 12.2
If we were to delete line 30 of Figure 12.5, which closes the connected descriptor, the code would still be correct, in the sense that there would be no memory leak. Why?

**Answer**: Even if we were to delete line 30 of Figure 12.5, the kernel would still ensure that there is no memory leak. When a process terminates for any reason, the kernel takes responsibility for closing all open file descriptors associated with that process. So, when the child process exits (in line 31), the kernel will automatically close the child's copy of the connected file descriptor, thereby preventing any memory leaks.

Line 30 in Figure 12.5 is not entirely redundant, even though the kernel would close the file descriptor when the child process exits. Explicitly closing the connected descriptor in line 30 is considered good programming practice for a few reasons:

1.  **Resource management**: Closing the connected descriptor as soon as it is no longer needed helps manage resources more efficiently. This ensures that the resources are released as soon as possible, rather than waiting for the process to exit.
    
2.  **Code clarity**: Explicitly closing the connected descriptor makes the code more readable and easier to understand. It demonstrates that the programmer is aware of the need to release resources and is actively managing them.
    
3.  **Preventing potential issues**: If the child process were to continue running for an extended period or have more complex logic, not closing the connected descriptor could lead to potential issues, such as running out of available file descriptors or causing unexpected behavior due to lingering connections.