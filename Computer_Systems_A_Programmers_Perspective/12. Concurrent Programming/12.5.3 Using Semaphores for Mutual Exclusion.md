## How do semaphores ensure mutually exclusive access to shared variables?

Semaphores ensure mutually exclusive access to shared variables by associating a semaphore `s`, initially set to 1, with each shared variable (or a related set of shared variables). The critical section is then surrounded by P(s) and V(s) operations. This approach creates a forbidden region where `s < 0` in the progress graph, preventing any feasible trajectory from touching the unsafe region, and thus ensuring that every feasible trajectory is safe.
![[Pasted image 20230428194930.png]]

## What is a binary semaphore and a counting semaphore?

A binary semaphore is a semaphore that is always either 0 or 1. Binary semaphores, when used for providing mutual exclusion, are often called mutexes. Locking a mutex is achieved by performing a P operation, and unlocking a mutex is achieved by performing a V operation. A thread that has locked but not yet unlocked a mutex is said to be holding the mutex.

A counting semaphore is a semaphore that is used as a counter for a set of available resources.

## How can semaphores be used to synchronize a counter program?

To synchronize a counter program using semaphores, follow these steps:
1. Declare a semaphore called `mutex`:
```c
volatile long cnt= 0;   /* Counter */
sem_t mutex;        /* Semaphore that protects counter */
```

2. Initialize the semaphore `mutex` to unity (1) in the main routine:
```c
Sem_init(&mutex, 0, 1); /* mutex = 1 */
```

3. Protect the update of the shared `cnt` variable in the thread routine by surrounding it with P and V operations:
```c
for (i = 0; i < niters; i++) {
    P(&mutex);
    cnt++;
    V(&mutex);
}
```
When the properly synchronized program is executed, it produces the correct results, regardless of the ordering of the instructions at runtime, ensuring mutually exclusive access to the shared variable.

## What are the limitations of progress graphs?

Progress graphs are useful for visualizing concurrent program execution on uniprocessors and understanding the need for synchronization. However, they have limitations when it comes to concurrent execution on multiprocessors, where a set of CPU/cache pairs share the same main memory. Multiprocessors can behave in ways that cannot be explained by progress graphs. In some cases, a multiprocessor memory system can be in a state that does not correspond to any trajectory in a progress graph.

### How should we approach synchronization on multiprocessors?

Despite the limitations of progress graphs when dealing with multiprocessors, the main message remains the same: always synchronize accesses to your shared variables, regardless of whether you're running on a uniprocessor or a multiprocessor. Synchronization is essential to ensure correct results and avoid race conditions or other synchronization issues.