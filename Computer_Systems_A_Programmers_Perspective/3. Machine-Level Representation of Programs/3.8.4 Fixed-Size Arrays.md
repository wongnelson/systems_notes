- The C compiler is able to make many optimizations for code operating on multidimensional arrays of fixed size

a) Original C code

```c

/* Compute i,k of fixed matrix product */
int fix_prod_ele (fix_matrix A, fix_matrix B, long i, long k) {
	long j;
	int result = 0;

	for (j = 0; j < N; j++)
	  result += A[i][j] * B[j][k];
	return result;
}
```

(b) Optimized C code

```c

1	/* Compute i,k of fixed matrix product */
2	int fix_prod_ele_opt(fix_matrix A, fix_matrix B, long i, long k) {
3		int *Aptr = &A[i][0];	/* Points to elements in row i of A		*/
4		int *Bptr = &B[0][k];	/* Points to elements in column k of B	*/
5		int *Bend = &B[N][k];	/* Marks stopping point for Bptr		*/
6		int result = 0;
7		do {					/* No need for initial test */
8			result += *Aptr * *Bptr;	/* Add next product to sum */
9			Aptr ++;			/* Move Aptr to next column */
10			Bptr += N;			/* Move Bptr to next row */
11		} while (Bptr != Bend);			/* Test for stopping point */
12		return result;
13	}
```
The optimized code in (b) is more cache-efficient than the original code. When the original code uses a for-loop, it accesses the elements of the matrix A and B in a scattered way. So the CPU has to spend more time going to and from main memory to cache to fetch data. This is called cache-miss and it incurs high memory access latency, which is the main reason why the original code runs slowly.

 The optimized code uses pointer arithmetic to access the elements of the matrices in a linear way. By using pointers, it keeps the row of matrix A and column of matrix B in contiguous memory location. So, the CPU can access them faster, this is called cache-hit, thus making the overall code execution faster. Additionally, the do-while loop eliminates the need for an initial test before entering the loop which reduces the instruction count and thus further speeds up the code.

q; why bptr += N
a; By incrementing the pointer "Bptr" by "N", we are effectively adding "N" times the size of the data type that the pointer is pointing to, to the memory address stored in the pointer. As the pointer "Bptr" is pointing to the elements of matrix B, which are ints, incrementing the pointer by "N" will add "N\*sizeof(int)" bytes to the memory address stored in the pointer. Since the matrix is a two-dimensional array, the layout of the array in memory will be a contiguous block of memory where each row is laid out next to the previous one. So, adding "N * sizeof(int)" bytes to the memory address stored in Bptr will move it to the next row in the matrix.

The following is the actual assembly code generated by gcc for function `fix_prod_ele`. We see that four registers are used as follows: `%eax` holds result, `%rdi` holds `Aptr, %rcx` holds `Bptr`, and `%rsi` holds `Bend`.

```c

	int fix_prod_ele_opt(fix_matrix A, fix_matrix B, long i, long k)
	A in %rdi, B in %rsi, i in %rdx, k in %rcx
1	fix_prod_ele:
2	  salq	 $6, %rdx		Compute 64 * i
3	  addq	 %rdx, %rdi		Compute Aptr = xA + 64i = &A[i][0]
4	  leaq	(%rsi,%rcx,4), %rcx	Compute Bptr = xB + 4k = &B[0][k]
5	  leaq	 1024(%rcx), %rsi	Compute Bend = xB + 4k + 1024 = &B[N][k]
6	  movl	 $0, %eax		Set result = 0
7	.L7:		loop:
8	  movl	(%rdi), %edx		Read *Aptr
9	  imull	(%rcx), %edx		Multiply by *Bptr
10	  addl	%edx, %eax		Add to result
11	  addq	$4, %rdi		Increment Aptr ++
12	  addq	$64, %rcx		Increment Bptr += N
13	  cmpq	%rsi, %rcx		Compare Bptr:Bend
14	  jne		.L7		If !=, goto loop
15	  rep; ret			Return
```

q; Why do we do "salq $6, %rdx "? Why 6 specifically
a; The instruction "salq $6, %rdx" is a bitwise left shift operation that shifts the contents of the register %rdx left by 6 bits. The effect of this is to multiply the value stored in %rdx by 2^6 = 64. The value of N is 1024 and the matrix is of int data type which is of 4 bytes. So each row is of 4_1024 = 4096 bytes. So 64 is used to compute 64_i which is the number of bytes from the beginning of the matrix to the start of the i-th row. This is done to compute the memory address of the start of the i-th row of matrix A, which is used to initialize the pointer "Aptr" in the optimized code It's a faster alternative than doing "leal i*4096(%rdi), %rdi" which takes more clock cycle.

4096 = 64^2. 64 is the size of the row/col

q; "The value of N is 1024" how do we know this?
a; In the original C code the value of N is not mentioned but in the assembly code, we see the instruction "leaq 1024(%rcx), %rsi" which is computing "Bend = xB + 4k + 1024 = &B[N][k]". where xB is the base address of the matrix B. we can see that the value being added to the base address is 1024 which gives us the assumption that the value of N is 1024.

Another way to know this is if we look at the number of bytes being added to the pointer Bptr in each iteration of the loop in lines 12, we can see that Bptr is incremented by 64 bytes each time. This is likely because the size of each row in the matrix is 4096 bytes and N is the number of elements in each row, which must be 4096/4 = 1024.

q; why is "salq $6, %rdx" the first instructin?
a; The instruction "salq $6, %rdx" is the first instruction in the function fix_prod_ele_opt because it's setting up a register for the use of the offset. The value of i (which is the row number we want to access) is passed as an argument to the function, it's stored in the register %rdx, then the instruction "salq $6, %rdx" is used to multiply the value of i by 64. The purpose of this instruction is to have a pre-calculated offset that will be used later in the function to calculate the memory address of the first element in the i-th row of matrix A, which is &A[i][0]. By doing this, instead of doing the calculation explicitly on every iteration, the offset is calculated once and stored in a register, making the calculation faster and more efficient. In this example, because the value of N is small, the optimization is not really necessary and the instruction salq is not used, but it's a general pattern used in many similar cases where the matrix size is larger.

#### 3.40
```c

/* Set all diagonal elements to val */
void fix_set_diag(fix_matrix A, int val) {
	long i;
	for (i = 0; i < N; i++)
	  A[i][i] = val;
}
```

When compiled with optimization level `-01, gcc` generates the following assembly code:

```c

1	fix_set_diag:
	void fix_set_diag(fix_matrix A, int val)
	A in %rdi, val in %rsi
2		movl	$0, %eax
3	.L13:
4		movl	%esi, (%rdi,%rax)
5		addq	$68, %rax
6		cmpq	$1088, %rax
7		jne	.L13
8		rep; ret
```

q; why move only the lower 32bit?
a; The instruction "movl %esi, (%rdi,%rax)" is moving the lower 32-bits of the %rsi register, because the data type being stored in the matrix "fix_matrix A" is int, which is typically 32-bit wide on most systems. So the compiler only needs to move the lower 32 bits of the value stored in the %rsi register, which contains the "val" argument, into the memory location that corresponds to the current index of the matrix. It is a trade-off between performance and memory usage: moving the full 64 bits would take more clock cycles to complete the operation and it would also require more memory to store the data, which could be a concern if you are working with large data set.

