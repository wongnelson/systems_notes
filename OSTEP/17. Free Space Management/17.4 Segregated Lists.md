[[9.9.14 Segregated Free Lists]]
## What are segregated lists in the context of memory allocation?

Segregated lists are a technique employed in memory allocation strategies to optimize performance and reduce fragmentation. The key idea behind segregated lists is the segregation of memory requests based on their size.

Here's an ASCII art representation of a simple segregated list implementation:

```
0-10 bytes:   [___] -> [___] -> [___] -> null
11-20 bytes:  [______] -> [______] -> null
21-30 bytes:  [_________] -> null
31-40 bytes:  [____________] -> [____________] -> [____________] -> null
```

Each row represents a different size class for memory blocks (e.g., 0-10 bytes, 11-20 bytes, etc.). Each block within a row is a free memory block of the corresponding size. The "->" arrow represents the pointer to the next free block in the list. 

When a request comes in for memory, the memory management system will look at the appropriate size class and select a free block from that list. If there isn't a suitable block in the exact size class, it might either look at the next largest size class or split a block from a larger size class to fit the request. 

Please note that the specifics can vary quite a bit depending on the implementation of the memory management system. The representation above is a very simplified example.


### How do segregated lists work?

In segregated list memory allocation, if an application frequently requests memory of a certain size, the allocator maintains a separate list specifically for managing memory chunks of that size. Requests that don't align with these popular sizes are forwarded to a more general memory allocator. 

### What are the benefits and complications of segregated lists?

The primary benefit of segregated lists is that they significantly reduce concerns about fragmentation. Additionally, if a request comes in that matches the size of the segregated list, the allocator can satisfy it quickly without needing to search an entire list.

However, this strategy also introduces new complications. One of the key questions is how to determine the amount of memory to dedicate to the specialized list versus the general memory pool. Balancing these can be a challenging task.

## How does the slab allocator utilize segregated lists?

The slab allocator, designed by Jeff Bonwick for use in the Solaris kernel, offers a clever solution to segregated list memory allocation. At boot time, the kernel allocates a number of "object caches" for frequently requested kernel objects, like locks and file-system inodes. Each of these caches is essentially a segregated free list of a specific size. 

When an object cache is running low on free space, it requests additional memory in the form of "slabs" from a more general memory allocator. Conversely, when a slab's objects are no longer in use, the general allocator can reclaim that memory.

Here's a simplified example of a segregated list allocator:

```c
#define NUM_LISTS 5

typedef struct {
    size_t size;
    node_t *head;
} seglist_t;

seglist_t seglists[NUM_LISTS];

void *seglist_alloc(size_t size) {
    for (int i = 0; i < NUM_LISTS; i++) {
        if (seglists[i].size >= size && seglists[i].head != NULL) {
            void *ptr = seglists[i].head;
            seglists[i].head = seglists[i].head->next;
            return ptr;
        }
    }
    // If no suitable block was found in the segregated lists, use a general allocator
    return general_alloc(size);
}
```

In this example, we have an array of segregated lists `seglists`, each holding a certain size of memory blocks. The `seglist_alloc` function first tries to find a suitable block in the segregated lists. If it can't find a suitable block, it resorts to a general-purpose allocator.

## What are the unique features of the slab allocator?

The slab allocator takes the segregated list approach a step further by keeping the objects in a pre-initialized state. This avoids the expensive operation of data structure initialization and destruction, significantly reducing the overhead. This is particularly useful when objects are frequently created and destroyed. This unique approach results in noticeable performance improvement.